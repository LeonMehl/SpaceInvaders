{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os.path\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, Flatten, ZeroPadding2D, UpSampling2D\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import pandas as pd \n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from scipy.signal import savgol_filter\n",
    "import math\n",
    "\n",
    "pathname = r\"D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\"\n",
    "datadirname = \"data\"\n",
    "testdirname = \"test\"\n",
    "validdirname = \"valid\"\n",
    "modeldirname = \"model\"\n",
    "datacsvname = \"data.csv\"\n",
    "modeljsonname=\"model-regr.json\"\n",
    "modelweightname=\"model-regr.h5\"\n",
    "dim = (50,50) \n",
    "actionstonum = {\"RIGHT\": 0,\n",
    "           \"LEFT\": 1,\n",
    "           \"SPACE\" : 2,\n",
    "          }\n",
    "numtoactions = {0: \"RIGHT\",\n",
    "           1: \"LEFT\",\n",
    "           2: \"SPACE\",\n",
    "          }\n",
    "scores = []\n",
    "overallscores = []\n",
    "\n",
    "\n",
    "def create_q_model():\n",
    "        # Network defined by the Deepmind paper\n",
    "        inputs = layers.Input(shape=(dim[0], dim[1], 3,))\n",
    "\n",
    "        # Convolutions on the frames on the screen\n",
    "        layer1 = layers.Conv2D(32, 8, strides=4, activation=\"relu\")(inputs)\n",
    "        layer2 = layers.Conv2D(64, 4, strides=2, activation=\"relu\")(layer1)\n",
    "        layer3 = layers.Conv2D(64, 3, strides=1, activation=\"relu\")(layer2)\n",
    "\n",
    "        layer4 = layers.Flatten()(layer3)\n",
    "\n",
    "        layer5 = layers.Dense(512, activation=\"relu\")(layer4)\n",
    "        action = layers.Dense(4, activation=\"linear\")(layer5)\n",
    "\n",
    "        return keras.Model(inputs=inputs, outputs=action)\n",
    "\n",
    "def run_game(learning_rate = 1.5e-06, epochs = 5, benchmin = 68.0):\n",
    "    manual = False\n",
    "    lr = [learning_rate for i in range(epochs)]\n",
    "\n",
    "    iterations = len(lr)\n",
    "    benches = []\n",
    "    qms = []\n",
    "    qps = []\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(iterations):\n",
    "        print(f\"{i}: learning rate: {lr[i]}\")\n",
    "        print(benchmin)\n",
    "        k = 2 #40\n",
    "        game = Game(500,500)\n",
    "        game.load_replay_memory()\n",
    "        for j in range(k):\n",
    "            #game.initialize(i, j)\n",
    "            game = Game(500,500,game.shufflelist)\n",
    "            game.run(j)\n",
    "        bench, qm, qp = game.print_benchmark()\n",
    "        benches.append(bench)\n",
    "        qms.append(qm)\n",
    "        qps.append(qp)\n",
    "        game.save_replay_memory()\n",
    "        game.save_checkpoint(f\"model-regr_{i}_{lr[i]:.9f}_{bench:.2f}.h5\")\n",
    "        if bench < benchmin:\n",
    "            benchmin = bench\n",
    "            game.save_checkpoint()\n",
    "        else:\n",
    "            counter += 1\n",
    "        if counter == 3:\n",
    "            counter = 0\n",
    "            lr = [i*0.5 for i in lr] \n",
    "            \n",
    "        overallscore = game.print_overall_score()\n",
    "        overallscores.append(overallscore)\n",
    "    return benches, qms, qps\n",
    "\n",
    "model = create_q_model()\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(pathname, modeldirname,modeljsonname), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(os.path.join(pathname, modeldirname,modelweightname))\n",
    "\n",
    "\n",
    "class Game:\n",
    "    screen = None\n",
    "    \n",
    "    lost = False\n",
    "    done = False\n",
    "\n",
    "    def __init__(self, width, height, shufflelist=[], lr=1e-3, checkpointparname=\"model-regr.h5\"):\n",
    "        pygame.init()\n",
    "        \n",
    "        self.aliens = []\n",
    "        self.rockets = []\n",
    "        \n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.screen = pygame.display.set_mode((int(width), int(height)))\n",
    "        self.screen.fill([255,0,0])\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        self.imgresh1 = None\n",
    "        self.imgresh2 = None\n",
    "\n",
    "        self.reward = 0\n",
    "        self.MAXREWARD = 1.0\n",
    "        self.PENALTY = -1.0\n",
    "        self.MOVEPENALTY = 0.0\n",
    "        \n",
    "        self.BATCHSIZE = 19\n",
    "        self.DISCOUNT = 0.99\n",
    "        self.ALPHA = 0.3\n",
    "        \n",
    "        manual=False\n",
    "        if manual == True:\n",
    "            self.EPSILON = 0.999\n",
    "        else:\n",
    "            self.EPSILON = 0.3\n",
    "        \n",
    "        self.REPLAYSIZE = 40_000\n",
    "        self.overall_score = 0\n",
    "        self.overall_numbatches = 0\n",
    "        self.overall_accumulatedstates = np.array([0.0,0.0,0.0,0.0])\n",
    "        \n",
    "        \n",
    "        self.path = os.path.join(pathname, datadirname)\n",
    "        self.modelpath =  os.path.join(pathname, modeldirname)\n",
    "        \n",
    "        self.filename = \"data.csv\"\n",
    "        \n",
    "        self.model = create_q_model()\n",
    "        self.model_target = create_q_model()\n",
    "\n",
    "        self.learningrate = lr\n",
    "        self.optimizer = keras.optimizers.Adam(learning_rate=self.learningrate, clipnorm=1.0)\n",
    "        self.loss_function = keras.losses.Huber()\n",
    "\n",
    "        self.checkpointname = os.path.join(pathname, modeldirname,checkpointparname)\n",
    "        print(f\"loading checkpoint: {self.checkpointname}\")\n",
    "        self.model_target.load_weights(self.checkpointname)\n",
    "        \n",
    "        self.overall_scores=[]\n",
    "        self.checkpoint_counter=0\n",
    "        \n",
    "        self.shufflelist = shufflelist\n",
    "        self.debugcounter = 0\n",
    "\n",
    "    \n",
    "\n",
    "        self.hero = Hero(self, width / 2, height - 20)\n",
    "        self.generator = Generator(self)\n",
    "        self.rocket = None\n",
    "\n",
    "    def run(self, i_index):\n",
    "        i = i_index + self.get_maxi() + 1\n",
    "        j = 0\n",
    "        while True:\n",
    "            img1 = np.frombuffer(pygame.image.tostring(self.screen, \"RGB\"), dtype=np.uint8)\n",
    "            self.imgresh1 = np.reshape(img1,(self.width,self.height, 3))\n",
    "            self.imgresh1 = cv2.resize(self.imgresh1, dim, interpolation = cv2.INTER_NEAREST )\n",
    "\n",
    "            current_state = np.array(self.imgresh1, dtype=np.float32)/255.0\n",
    "\n",
    "            #if len(self.aliens) == 0:\n",
    "            #    self.displayText(\"WIN\")\n",
    "\n",
    "            pressed = pygame.key.get_pressed()\n",
    "            if pressed[pygame.K_LEFT]:  # sipka doleva\n",
    "                self.hero.x -= 2 if self.hero.x > 20 else 0  # leva hranice plochy\n",
    "            elif pressed[pygame.K_RIGHT]:  # sipka doprava\n",
    "                self.hero.x += 2 if self.hero.x < self.width - 20 else 0  # prava hranice\n",
    "            elif pressed[pygame.K_q]:\n",
    "                break\n",
    "\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    self.reward = self.PENALTY\n",
    "                    pygame.display.flip()                         \n",
    "                    pygame.quit()\n",
    "                    break\n",
    "                if event.type == pygame.KEYDOWN and event.key == pygame.K_SPACE and not self.lost:\n",
    "                    self.rockets.append(Rocket(self, self.hero.x, self.hero.y))\n",
    "\n",
    "            pygame.display.flip()\n",
    "            self.clock.tick(60)\n",
    "            self.screen.fill((255, 0, 0))\n",
    "\n",
    "            for alien in self.aliens:\n",
    "                alien.draw()\n",
    "                alien.checkCollision(self)\n",
    "                if (alien.y > self.height):\n",
    "                    pygame.display.flip()                         \n",
    "                    pygame.quit()\n",
    "                    return\n",
    "                    \n",
    "            for rocket in self.rockets:\n",
    "                rocket.draw()\n",
    "\n",
    "            if not self.lost: self.hero.draw()\n",
    "                \n",
    "            img2 = np.frombuffer(pygame.image.tostring(self.screen, \"RGB\"), dtype=np.uint8)\n",
    "            #self.imgresh2 = np.reshape(img2,(self.width,self.height, 3))\n",
    "            self.imgresh2 = cv2.resize(img2, dim, interpolation = cv2.INTER_NEAREST )\n",
    "\n",
    "            self.write(i,j)\n",
    "\n",
    "            j+=1\n",
    "\n",
    "    def write(self, i, j): \n",
    "\n",
    "        cv2.imwrite(os.path.join(self.path,\"current_{}_{}.png\".format(i,j)), self.imgresh1)\n",
    "        cv2.imwrite(os.path.join(self.path,\"next_{}_{}.png\".format(i,j)), self.imgresh2)\n",
    "\n",
    "    def train(self, i, j, term):\n",
    "        \n",
    "        # https://pythonprogramming.net/training-deep-q-learning-dqn-reinforcement-learning-python-tutorial/\n",
    "        \n",
    "        currentstate = \"current_{}_{}.png\".format(i,j)\n",
    "\n",
    "        nextstate = \"next_{}_{}.png\".format(i,j)      \n",
    "        \n",
    "        batch, files = self.pop_batch(self.BATCHSIZE)\n",
    "        \n",
    "        assert(self.imgresh1.shape == (dim[0], dim[1],3))\n",
    "        assert(self.imgresh2.shape == (dim[0], dim[1],3))\n",
    "        \n",
    "        batch.append([self.imgresh1, actionstonum[self.changeto], self.reward, self.imgresh2, term, self.snake_pos[0], self.snake_pos[1], self.food_pos[0], self.food_pos[1]])\n",
    "        files.append((\"current_{}_{}.png\".format(i,j), \"next_{}_{}.png\".format(i,j)))\n",
    "        \n",
    "        self.write(i,j)\n",
    "         \n",
    "        self.backprop(batch)\n",
    "        \n",
    "        self.numbatches += 1\n",
    "            \n",
    "        self.push_batch(batch, files)   \n",
    "  \n",
    "        return    \n",
    "    \n",
    "    def get_maxi(self):\n",
    "        \n",
    "        maxi = 0\n",
    "        \n",
    "        for item in self.shufflelist:\n",
    "            curr = item[0]\n",
    "            s = re.findall(r'\\d+', curr)[0]\n",
    "            if int(s) > maxi:\n",
    "                maxi = int(s)\n",
    "        \n",
    "        return maxi\n",
    "    \n",
    "    def load_replay_memory(self):\n",
    "\n",
    "        f = open(os.path.join(os.path.join(self.path,datacsvname)), \"r\")\n",
    "        \n",
    "        df = pd.read_csv(f, index_col = 0) \n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "\n",
    "            currentpicname = row[\"currentstate\"]\n",
    "            action = actionstonum[row[\"action\"]]\n",
    "            reward = row[\"reward\"]\n",
    "            nextpicname = row[\"nextstate\"]\n",
    "            terminated = row[\"terminated\"]\n",
    "\n",
    "            assert os.path.isfile(os.path.join(self.path,currentpicname)) == True\n",
    "            assert (action < 5 and action >= 0)\n",
    "            assert isinstance(reward,int) or isinstance(reward, float)\n",
    "            assert os.path.isfile(os.path.join(self.path,nextpicname)) == True\n",
    "            \n",
    "            self.shufflelist.append([currentpicname,action,reward,nextpicname, terminated])\n",
    "\n",
    "        random.shuffle(self.shufflelist)\n",
    "        \n",
    "        #print(self.shufflelist)\n",
    "\n",
    "        #print(f\"loading: size of replay memory {len(self.shufflelist)}\")\n",
    "        \n",
    "        f.close()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def save_replay_memory(self):\n",
    "        \n",
    "        assert os.path.isfile(os.path.join(self.path,datacsvname)) == True\n",
    "        \n",
    "        data = []\n",
    "        \n",
    "        if len(self.shufflelist) == 0:\n",
    "            return\n",
    "        \n",
    "        if len(self.shufflelist) > self.REPLAYSIZE:\n",
    "            \n",
    "            self.numbatches = len(self.shufflelist) - self.REPLAYSIZE\n",
    "            self.overall_numbatches += self.numbatches\n",
    "            \n",
    "            for i in range(len(self.shufflelist) - self.REPLAYSIZE):\n",
    "                item = self.shufflelist.pop(0)\n",
    "                assert os.path.isfile(os.path.join(self.path,item[0])) == True\n",
    "                assert os.path.isfile(os.path.join(self.path,item[3])) == True\n",
    "                os.remove(os.path.join(self.path,item[0]))\n",
    "                os.remove(os.path.join(self.path,item[3]))\n",
    "                \n",
    "        for (cs, act, rew, fs, term) in self.shufflelist:\n",
    "            \n",
    "            data.append({'currentstate': cs, 'action': numtoactions[act], 'reward': rew, 'nextstate': fs, 'terminated': term})\n",
    "            \n",
    "        df = pd.DataFrame(data) \n",
    "        \n",
    "        df.to_csv(os.path.join(self.path, self.filename)) \n",
    "        \n",
    "        #print(f\"saving: size of replay memory {len(self.shufflelist)}\")\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def print_benchmark(self):\n",
    "\n",
    "        maxlist = []\n",
    "        penaltylist = []\n",
    "        averagestates = [0,0,0,0]\n",
    "        averagepenalty = [0,0,0,0]\n",
    "        pmerror = 0\n",
    "        pterror = 0\n",
    "\n",
    "        for (cs, act, rew, fs, term) in self.shufflelist:\n",
    "            if rew == self.MAXREWARD or rew == 30.0:\n",
    "                maxlist.append((cs,act,rew,fs,term))\n",
    "            if rew == self.PENALTY:\n",
    "                penaltylist.append((cs,act,rew,fs,term))\n",
    "        print(f\"Number of maxrewards in shufflelist: {len(maxlist)}, perc: {100*len(maxlist)/len(self.shufflelist)}\")\n",
    "        print(f\"Number of terminations in shufflelist: {len(penaltylist)}, perc: {100*len(penaltylist)/len(self.shufflelist)}\")\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        print(\"Testing maxlist\")\n",
    "        for i in range(len(maxlist)):\n",
    "            img = cv2.imread(os.path.join(pathname, datadirname, maxlist[i][0]),cv2.IMREAD_COLOR )\n",
    "            states = self.model.predict(np.array([img])/255.0, batch_size=1, verbose=0)[0]\n",
    "            averagestates += states\n",
    "            if np.argmax(states) != maxlist[i][1]:\n",
    "                count += 1\n",
    "            pmerror = 100*count/len(maxlist)\n",
    "        print(f\"Number of predicted errors in maxlist: {count}, perc: {pmerror}\")\n",
    "        print(f\"Q Values for max: {averagestates/len(maxlist)}\")\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        print(\"Testing penaltylist\") \n",
    "        for i in range(len(penaltylist)):\n",
    "            img = cv2.imread(os.path.join(pathname, datadirname, penaltylist[i][0]),cv2.IMREAD_COLOR )\n",
    "            states = self.model.predict(np.array([img])/255.0, batch_size=1, verbose=0)[0]\n",
    "            averagepenalty += states\n",
    "            if np.argmax(states) == penaltylist[i][1]:\n",
    "                count += 1\n",
    "            pterror = 100*count/len(penaltylist)\n",
    "        print(f\"Number of predicted terminations in penaltylist: {count}, perc: {pterror}\")\n",
    "        print(f\"Q Values for penalty: {[i/len(penaltylist) for i in averagepenalty]}\")\n",
    "        \n",
    "        return pmerror, [i/len(maxlist) for i in averagestates], [i/len(penaltylist) for i in averagepenalty]\n",
    "    \n",
    "    def save_checkpoint(self, checkpointparname=modelweightname):\n",
    "                                                                         \n",
    "        self.model_target.set_weights(self.model.get_weights())\n",
    "        print(f\"saving checkpoint: {os.path.join(pathname, modeldirname,checkpointparname)}\")\n",
    "        self.model_target.save_weights(os.path.join(pathname, modeldirname,checkpointparname) )\n",
    "            \n",
    "        return\n",
    "\n",
    "    def print_score(self):\n",
    "        print(f\" ----> TIME IS {datetime.now():%Y-%m-%d_%H-%M-%S}\")\n",
    "        print(f\" ----> SCORE is {self.score}\")\n",
    "        print(f\" ----> NUM OF BATCHES is {self.numbatches}\")\n",
    "        return self.score, self.numbatches\n",
    "    \n",
    "    def print_overall_score(self):\n",
    "        print(f\"--> TIME IS {datetime.now():%Y-%m-%d_%H-%M-%S}\")\n",
    "        print(f\"--> OVERALL SCORE is {self.overall_score}\")\n",
    "        print(f\"--> OVERALL NUM OF BATCHES is {self.overall_numbatches}\")\n",
    "        return self.overall_score, self.overall_numbatches     \n",
    "    \n",
    "\n",
    "\n",
    "class Alien:\n",
    "    def __init__(self, game, x, y):\n",
    "        self.x = x\n",
    "        self.game = game\n",
    "        self.y = y\n",
    "        self.size = 40\n",
    "\n",
    "    def draw(self):\n",
    "        pygame.draw.rect(self.game.screen,  # renderovací plocha\n",
    "                         (81, 43, 88),  # barva objektu\n",
    "                         pygame.Rect(self.x, self.y, self.size, self.size))\n",
    "        self.y += 0.4\n",
    "\n",
    "    def checkCollision(self, game):\n",
    "        for rocket in game.rockets:\n",
    "            if (rocket.x < self.x + self.size and\n",
    "                    rocket.x > self.x - self.size and\n",
    "                    rocket.y < self.y + self.size and\n",
    "                    rocket.y > self.y - self.size):\n",
    "                game.rockets.remove(rocket)\n",
    "                game.aliens.remove(self)\n",
    "\n",
    "\n",
    "class Hero:\n",
    "    def __init__(self, game, x, y):\n",
    "        self.x = x\n",
    "        self.game = game\n",
    "        self.y = y\n",
    "\n",
    "    def draw(self):\n",
    "        pygame.draw.rect(self.game.screen,\n",
    "                         (210, 250, 251),\n",
    "                         pygame.Rect(self.x, self.y, 40, 20))\n",
    "\n",
    "\n",
    "class Generator:\n",
    "    def __init__(self, game):\n",
    "        margin = 30  # mezera od okraju obrazovky\n",
    "        width = 50  # mezera mezi alieny\n",
    "        for x in range(margin, game.width - margin, width):\n",
    "            for y in range(margin, int(game.height / 2), width):\n",
    "                if(random.randint(0,1)==1):\n",
    "                    game.aliens.append(Alien(game, x, y))\n",
    "                \n",
    "                \n",
    "\n",
    "        # game.aliens.append(Alien(game, 280, 50))\n",
    "\n",
    "\n",
    "class Rocket:\n",
    "    def __init__(self, game, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.game = game\n",
    "\n",
    "    def draw(self):\n",
    "        pygame.draw.rect(self.game.screen,  # renderovací plocha\n",
    "                         (254, 52, 110),  # barva objektu\n",
    "                         pygame.Rect(self.x, self.y, 15, 15))\n",
    "        self.y -= 2  # poletí po herní ploše nahoru 2px/snímek\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    " #   game = Game(500, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: learning rate: 1.5e-06\n",
      "60.0\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "Number of maxrewards in shufflelist: 96, perc: 14.285714285714286\n",
      "Number of terminations in shufflelist: 64, perc: 9.523809523809524\n",
      "Testing maxlist\n",
      "Number of predicted errors in maxlist: 32, perc: 33.333333333333336\n",
      "Q Values for max: [-0.00599414 -0.00305563  0.00524076 -0.00410843]\n",
      "Testing penaltylist\n",
      "Number of predicted terminations in penaltylist: 32, perc: 50.0\n",
      "Q Values for penalty: [-0.00879652239382267, 8.417724166065454e-05, 0.01357804099097848, -0.015757187269628048]\n",
      "saving checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr_0_0.000001500_33.33.h5\n",
      "saving checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "--> TIME IS 2020-11-10_16-03-18\n",
      "--> OVERALL SCORE is 0\n",
      "--> OVERALL NUM OF BATCHES is 0\n",
      "1: learning rate: 1.5e-06\n",
      "33.333333333333336\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "Number of maxrewards in shufflelist: 192, perc: 14.285714285714286\n",
      "Number of terminations in shufflelist: 128, perc: 9.523809523809524\n",
      "Testing maxlist\n",
      "Number of predicted errors in maxlist: 64, perc: 33.333333333333336\n",
      "Q Values for max: [ 0.00080203 -0.00401543 -0.00030756  0.00160239]\n",
      "Testing penaltylist\n",
      "Number of predicted terminations in penaltylist: 0, perc: 0.0\n",
      "Q Values for penalty: [-0.0008539488480892032, -0.01077083870768547, -0.0034492413979023695, 4.2445317376405e-05]\n",
      "saving checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr_1_0.000001500_33.33.h5\n",
      "--> TIME IS 2020-11-10_16-03-29\n",
      "--> OVERALL SCORE is 0\n",
      "--> OVERALL NUM OF BATCHES is 0\n",
      "2: learning rate: 1.5e-06\n",
      "33.333333333333336\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "Number of maxrewards in shufflelist: 384, perc: 14.285714285714286\n",
      "Number of terminations in shufflelist: 256, perc: 9.523809523809524\n",
      "Testing maxlist\n",
      "Number of predicted errors in maxlist: 256, perc: 66.66666666666667\n",
      "Q Values for max: [-0.00111866  0.00475006  0.00344533 -0.00033917]\n",
      "Testing penaltylist\n",
      "Number of predicted terminations in penaltylist: 128, perc: 50.0\n",
      "Q Values for penalty: [0.000698453193763271, 0.008202211000025272, 0.001141363987699151, 0.002284822054207325]\n",
      "saving checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr_2_0.000001500_66.67.h5\n",
      "--> TIME IS 2020-11-10_16-03-49\n",
      "--> OVERALL SCORE is 0\n",
      "--> OVERALL NUM OF BATCHES is 0\n",
      "3: learning rate: 1.5e-06\n",
      "33.333333333333336\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "Number of maxrewards in shufflelist: 768, perc: 14.285714285714286\n",
      "Number of terminations in shufflelist: 512, perc: 9.523809523809524\n",
      "Testing maxlist\n",
      "Number of predicted errors in maxlist: 256, perc: 33.333333333333336\n",
      "Q Values for max: [ 0.00440722 -0.00174596  0.00048107 -0.00075493]\n",
      "Testing penaltylist\n",
      "Number of predicted terminations in penaltylist: 0, perc: 0.0\n",
      "Q Values for penalty: [0.01396444858983159, -0.003857759525999427, 0.004075196105986834, -0.0023590895580127835]\n",
      "saving checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr_3_0.000001500_33.33.h5\n",
      "--> TIME IS 2020-11-10_16-04-27\n",
      "--> OVERALL SCORE is 0\n",
      "--> OVERALL NUM OF BATCHES is 0\n",
      "4: learning rate: 7.5e-07\n",
      "33.333333333333336\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "Number of maxrewards in shufflelist: 1536, perc: 14.285714285714286\n",
      "Number of terminations in shufflelist: 1024, perc: 9.523809523809524\n",
      "Testing maxlist\n",
      "Number of predicted errors in maxlist: 1024, perc: 66.66666666666667\n",
      "Q Values for max: [-0.00291759 -0.00015566 -0.00511588  0.00121039]\n",
      "Testing penaltylist\n",
      "Number of predicted terminations in penaltylist: 0, perc: 0.0\n",
      "Q Values for penalty: [-0.0036024704459123313, -0.003378436085768044, -0.011911569628864527, 0.004866235889494419]\n",
      "saving checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr_4_0.000000750_66.67.h5\n",
      "--> TIME IS 2020-11-10_16-06-05\n",
      "--> OVERALL SCORE is 0\n",
      "--> OVERALL NUM OF BATCHES is 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([33.333333333333336,\n",
       "  33.333333333333336,\n",
       "  66.66666666666667,\n",
       "  33.333333333333336,\n",
       "  66.66666666666667],\n",
       " [[-0.0059941372989366455,\n",
       "   -0.003055631648749113,\n",
       "   0.005240759424244364,\n",
       "   -0.004108425695449114],\n",
       "  [0.0008020286913961172,\n",
       "   -0.004015434145306547,\n",
       "   -0.0003075614416350921,\n",
       "   0.0016023863572627306],\n",
       "  [-0.0011186619328024487,\n",
       "   0.0047500610041121645,\n",
       "   0.0034453279028336206,\n",
       "   -0.0003391734887069712],\n",
       "  [0.004407218812654416,\n",
       "   -0.001745964555690686,\n",
       "   0.00048107355056951445,\n",
       "   -0.0007549321744590998],\n",
       "  [-0.002917591637621323,\n",
       "   -0.0001556643983349204,\n",
       "   -0.005115877216060956,\n",
       "   0.0012103892804589123]],\n",
       " [[-0.00879652239382267,\n",
       "   8.417724166065454e-05,\n",
       "   0.01357804099097848,\n",
       "   -0.015757187269628048],\n",
       "  [-0.0008539488480892032,\n",
       "   -0.01077083870768547,\n",
       "   -0.0034492413979023695,\n",
       "   4.2445317376405e-05],\n",
       "  [0.000698453193763271,\n",
       "   0.008202211000025272,\n",
       "   0.001141363987699151,\n",
       "   0.002284822054207325],\n",
       "  [0.01396444858983159,\n",
       "   -0.003857759525999427,\n",
       "   0.004075196105986834,\n",
       "   -0.0023590895580127835],\n",
       "  [-0.0036024704459123313,\n",
       "   -0.003378436085768044,\n",
       "   -0.011911569628864527,\n",
       "   0.004866235889494419]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_game(1.5e-06, 5, 60.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
