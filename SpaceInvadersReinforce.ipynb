{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os.path\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, Flatten, ZeroPadding2D, UpSampling2D\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import pandas as pd \n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from scipy.signal import savgol_filter\n",
    "import math\n",
    "import time\n",
    "import statistics\n",
    "\n",
    "pathname = r\"D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\"\n",
    "datadirname = \"data_new\"\n",
    "testdirname = \"test\"\n",
    "validdirname = \"valid\"\n",
    "modeldirname = \"model\"\n",
    "datacsvname = \"data.csv\"\n",
    "modeljsonname=\"model-regr.json\"\n",
    "modelweightname=\"model-regr.h5\"\n",
    "dim = (50,50) \n",
    "actionstonum = {\"RIGHT\": 0,\n",
    "           \"LEFT\": 1,\n",
    "           \"SPACE\" : 2,\n",
    "          }\n",
    "numtoactions = {0: \"RIGHT\",\n",
    "           1: \"LEFT\",\n",
    "           2: \"SPACE\",\n",
    "          }\n",
    "scores = []\n",
    "overallscores = []\n",
    "manual = False\n",
    "\n",
    "\n",
    "def create_q_model():\n",
    "        # Network defined by the Deepmind paper\n",
    "        inputs = layers.Input(shape=(dim[0], dim[1], 3,))\n",
    "\n",
    "        # Convolutions on the frames on the screen\n",
    "        layer1 = layers.Conv2D(32, 8, strides=4, activation=\"relu\")(inputs)\n",
    "        layer2 = layers.Conv2D(64, 4, strides=2, activation=\"relu\")(layer1)\n",
    "        layer3 = layers.Conv2D(64, 3, strides=1, activation=\"relu\")(layer2)\n",
    "\n",
    "        layer4 = layers.Flatten()(layer3)\n",
    "\n",
    "        layer5 = layers.Dense(512, activation=\"relu\")(layer4)\n",
    "        action = layers.Dense(3, activation=\"linear\")(layer5)\n",
    "\n",
    "        return keras.Model(inputs=inputs, outputs=action)\n",
    "\n",
    "def run_game(learning_rate = 1.5e-06, epochs = 5, benchmin = 68.0):\n",
    "    lr = [learning_rate for i in range(epochs)]\n",
    "\n",
    "    iterations = len(lr)\n",
    "    benches = []\n",
    "    qms = []\n",
    "    qps = []\n",
    "    counter = 0\n",
    "    epsilon = 0.25\n",
    "\n",
    "    for i in range(iterations):\n",
    "        print(f\"{i}: learning rate: {lr[i]}\")\n",
    "        print(benchmin)\n",
    "        k = 3\n",
    "        game = Game(500,500, epsilon)\n",
    "        epsilon *= 0.9\n",
    "        game.load_replay_memory()\n",
    "        for j in range(k):\n",
    "            game.initialize()\n",
    "            game.run(j)\n",
    "        bench, qm, qp = game.print_benchmark()\n",
    "        benches.append(bench)\n",
    "        qms.append(qm)\n",
    "        qps.append(qp)\n",
    "        game.save_replay_memory()\n",
    "        game.save_checkpoint(f\"model-regr_{i}_{lr[i]:.9f}_{bench:.2f}.h5\")\n",
    "        if bench < benchmin:\n",
    "            benchmin = bench\n",
    "            game.save_checkpoint()\n",
    "            #lr = [i*0.5 for i in lr] \n",
    "        else:\n",
    "            counter += 1\n",
    "        if counter == 3 and lr[i] > 1e-6:\n",
    "            counter = 0\n",
    "            lr = [i*0.5 for i in lr] \n",
    "            \n",
    "    print(\"Scores: \", overallscores)\n",
    "\n",
    "    return benches, qms, qps\n",
    "\n",
    "model = create_q_model()\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(pathname, modeldirname,modeljsonname), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(os.path.join(pathname, modeldirname,modelweightname))\n",
    "\n",
    "\n",
    "class Game:\n",
    "    screen = None\n",
    "    \n",
    "    lost = False\n",
    "    done = False\n",
    "\n",
    "    def __init__(self, width, height, epsilon, lr=1e-3, checkpointparname=\"model-regr.h5\"):\n",
    "        \n",
    "        self.currentAction = \"\"\n",
    "                       \n",
    "        self.shufflelist = []\n",
    "        \n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.screen = pygame.display.set_mode((int(width), int(height)))\n",
    "        self.screen.fill([255,0,0])\n",
    "\n",
    "        self.imgresh1 = None\n",
    "        self.imgresh2 = None\n",
    "\n",
    "        self.reward = 0\n",
    "        self.MAXREWARD = 5\n",
    "        self.HITREWARD = 2\n",
    "        self.PENALTY = -4\n",
    "        self.FIREPENALTY = -2 \n",
    "        self.MOVEPENALTY = 0\n",
    "        self.NOTFIREPENALTY = -3\n",
    "        \n",
    "        self.BATCHSIZE = 19\n",
    "        self.DISCOUNT = 0.99\n",
    "        self.ALPHA = 0.3\n",
    "        \n",
    "        \n",
    "        self.EPSILON = epsilon\n",
    "        \n",
    "        self.ALIENPROB = 0.4\n",
    "        \n",
    "        self.REPLAYSIZE = 40_000\n",
    "        self.overall_score = 0\n",
    "        self.overall_numbatches = 0\n",
    "        self.overall_accumulatedstates = np.array([0.0,0.0,0.0,0.0])\n",
    "        \n",
    "        self.scores = []\n",
    "        \n",
    "        \n",
    "        self.path = os.path.join(pathname, datadirname)\n",
    "        self.modelpath =  os.path.join(pathname, modeldirname)\n",
    "        \n",
    "        self.filename = \"data.csv\"\n",
    "        \n",
    "        self.model = create_q_model()\n",
    "        self.model_target = create_q_model()\n",
    "\n",
    "        self.learningrate = lr\n",
    "        self.optimizer = keras.optimizers.Adam(learning_rate=self.learningrate, clipnorm=1.0)\n",
    "        self.loss_function = keras.losses.Huber()\n",
    "\n",
    "        self.checkpointname = os.path.join(pathname, modeldirname,checkpointparname)\n",
    "        print(f\"loading checkpoint: {self.checkpointname}\")\n",
    "        self.model_target.load_weights(self.checkpointname)\n",
    "        \n",
    "        self.overall_scores=[]\n",
    "        self.checkpoint_counter=0\n",
    "        \n",
    "        self.debugcounter = 0\n",
    "\n",
    "        \n",
    "    def initialize(self):\n",
    "        pygame.init()\n",
    "        self.aliens = []\n",
    "        self.rockets = []\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.hero = Hero(self, self.width / 2, self.height - 20)\n",
    "        self.firstFire = True\n",
    "        \n",
    "        #Generator\n",
    "        margin = 30  # mezera od okraju obrazovky\n",
    "        width = 50  # mezera mezi alieny\n",
    "        self.screen = pygame.display.set_mode((int(self.width), int(self.height)))\n",
    "        for x in range(margin, self.width - margin, width):\n",
    "            for y in range(margin, int(self.height / 2), width):\n",
    "                if(random.random()<=self.ALIENPROB):\n",
    "                    self.aliens.append(Alien(self, x, y))\n",
    "                    \n",
    "        self.rocket = None\n",
    "        self.numbatches = 0\n",
    "        \n",
    "        self.model.load_weights(self.checkpointname)\n",
    "    \n",
    "\n",
    "    def run(self, i_index):\n",
    "        i = i_index + self.get_maxi() + 1\n",
    "        j = 0\n",
    "        while True:\n",
    "            img1 = np.frombuffer(pygame.image.tostring(self.screen, \"RGB\"), dtype=np.uint8)\n",
    "            self.imgresh1 = np.reshape(img1,(self.width,self.height, 3))\n",
    "            self.imgresh1 = cv2.resize(self.imgresh1, dim, interpolation = cv2.INTER_NEAREST )\n",
    "            self.imgresh1 = cv2.cvtColor(self.imgresh1, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            current_state = np.array(self.imgresh1, dtype=np.float32)/255.0\n",
    "            state_tensor = tf.convert_to_tensor(current_state)\n",
    "            state_tensor = tf.expand_dims(state_tensor, 0)\n",
    "            action_probs = self.model(state_tensor, training=False)\n",
    "            theaction = tf.argmax(action_probs[0]).numpy()            \n",
    "\n",
    "            #win\n",
    "            if len(self.aliens) == 0:\n",
    "                pygame.display.flip()                         \n",
    "                pygame.quit()\n",
    "                return\n",
    "\n",
    "            pressed = pygame.key.get_pressed()\n",
    "            if pressed[pygame.K_LEFT]:\n",
    "                self.currentAction = \"LEFT\"\n",
    "                \n",
    "            elif pressed[pygame.K_RIGHT]:\n",
    "                self.currentAction = \"RIGHT\"\n",
    "                \n",
    "            elif pressed[pygame.K_q]:\n",
    "                pygame.display.flip()                         \n",
    "                pygame.quit()\n",
    "                return\n",
    "\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.KEYDOWN and event.key == pygame.K_SPACE and not self.lost:\n",
    "                    self.currentAction = \"SPACE\"\n",
    "                \n",
    "            if manual != True:\n",
    "                if np.random.random() > self.EPSILON:\n",
    "                    self.currentAction = numtoactions[theaction]\n",
    "                else:\n",
    "                    self.currentAction = numtoactions[random.randint(0,2)]\n",
    "\n",
    "                \n",
    "            if self.currentAction == \"RIGHT\":\n",
    "                self.hero.x += 6 if self.hero.x < self.width - 20 else 0  # prava hranice\n",
    "                self.reward = self.MOVEPENALTY\n",
    "                \n",
    "            if self.currentAction == \"LEFT\":\n",
    "                self.hero.x -= 6 if self.hero.x > 20 else 0  # leva hranice plochy\n",
    "                self.reward = self.MOVEPENALTY\n",
    "            \n",
    "            if len(self.rockets) == 0:\n",
    "                self.firstFire = True\n",
    "            \n",
    "            if self.currentAction == \"SPACE\":\n",
    "                if self.firstFire or self.rockets[-1].y + self.rockets[-1].size < self.hero.y:\n",
    "                    self.rockets.append(Rocket(self, self.hero.x, self.hero.y))\n",
    "                    if self.checkHit(self.rockets[-1]):\n",
    "                        self.reward = self.HITREWARD\n",
    "                        self.train(i,j, False)\n",
    "                    else:\n",
    "                        self.reward = self.FIREPENALTY\n",
    "                        self.train(i,j, False)\n",
    "                else:\n",
    "                    reward = self.NOTFIREPENALTY\n",
    "                self.firstFire = False\n",
    "            \n",
    "            if manual == True:\n",
    "                self.currentAction = \"LEFT\"\n",
    "\n",
    "            pygame.display.flip()\n",
    "            self.clock.tick(60)\n",
    "            self.screen.fill((255, 0, 0))\n",
    "\n",
    "            for alien in self.aliens:\n",
    "                alien.draw()\n",
    "                alien.checkCollision(self)\n",
    "                if (alien.y > (self.height-60)):\n",
    "                    self.reward = self.PENALTY\n",
    "                    self.train(i,j, True)\n",
    "                    self.scores.append(len(self.aliens))\n",
    "                    pygame.display.flip()                         \n",
    "                    pygame.quit()\n",
    "                    return\n",
    "                    \n",
    "            for rocket in self.rockets:\n",
    "                rocket.draw()\n",
    "\n",
    "            if not self.lost: self.hero.draw()\n",
    "                \n",
    "            img2 = np.frombuffer(pygame.image.tostring(self.screen, \"RGB\"), dtype=np.uint8)\n",
    "            self.imgresh2 = np.reshape(img2,(self.width,self.height, 3))\n",
    "            self.imgresh2 = cv2.resize(img2, dim, interpolation = cv2.INTER_NEAREST )\n",
    "            self.imgresh2 = cv2.cvtColor(self.imgresh2, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            if j > 0:\n",
    "                if j%4 == 0:\n",
    "                    self.train(i,j, False)\n",
    "\n",
    "            j+=1\n",
    "\n",
    "    def checkHit(self, rocket):\n",
    "        for alien in self.aliens:\n",
    "            if (rocket.x < alien.x + alien.size and \n",
    "                    rocket.x + rocket.size > alien.x and\n",
    "                    not alien.will_be_hit):\n",
    "                alien.will_be_hit = True\n",
    "                return True\n",
    "            \n",
    "            \n",
    "    def write(self, i, j): \n",
    "\n",
    "        cv2.imwrite(os.path.join(self.path,\"current_{}_{}.png\".format(i,j)), self.imgresh1)\n",
    "        cv2.imwrite(os.path.join(self.path,\"next_{}_{}.png\".format(i,j)), self.imgresh2)\n",
    "\n",
    "    def train(self, i, j, term):\n",
    "        \n",
    "        # https://pythonprogramming.net/training-deep-q-learning-dqn-reinforcement-learning-python-tutorial/\n",
    "        \n",
    "        currentstate = \"current_{}_{}.png\".format(i,j)\n",
    "\n",
    "        nextstate = \"next_{}_{}.png\".format(i,j)      \n",
    "        \n",
    "        batch, files = self.pop_batch(self.BATCHSIZE)\n",
    "        \n",
    "        assert(self.imgresh1.shape == (dim[0], dim[1],3))\n",
    "        assert(self.imgresh2.shape == (dim[0], dim[1],3))\n",
    "        \n",
    "        batch.append([self.imgresh1, actionstonum[self.currentAction], self.reward, self.imgresh2, term])\n",
    "        files.append((\"current_{}_{}.png\".format(i,j), \"next_{}_{}.png\".format(i,j)))\n",
    "        \n",
    "        self.write(i,j)\n",
    "         \n",
    "        self.backprop(batch)\n",
    "        \n",
    "        self.numbatches += 1\n",
    "            \n",
    "        self.push_batch(batch, files)   \n",
    "  \n",
    "        return    \n",
    "\n",
    "    def backprop(self, batch):\n",
    "\n",
    "        rewards_sample = [batch[i][2] for i in range(len(batch))]\n",
    "        action_sample = [batch[i][1] for i in range(len(batch))]\n",
    "      \n",
    "        done_sample = tf.convert_to_tensor([float(batch[i][4]) for i in range(len(batch))])\n",
    "\n",
    "        X =  self.get_X(batch, 0)\n",
    "        Xf = self.get_X(batch, 3)\n",
    "        future_rewards = self.model_target.predict(Xf)\n",
    "\n",
    "        updated_q_values = rewards_sample + 0.99 * tf.reduce_max(future_rewards, axis=1)\n",
    "        updated_q_values = updated_q_values * (1 - done_sample) - done_sample*abs(self.PENALTY)\n",
    "\n",
    "    \n",
    "        masks = tf.one_hot(action_sample, 3)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Train the model on the states and updated Q-values\n",
    "            q_values = self.model(X)\n",
    "\n",
    "            # Apply the masks to the Q-values to get the Q-value for action taken\n",
    "            q_action = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
    "            # Calculate loss between new Q-value and old Q-value\n",
    "            loss = self.loss_function(updated_q_values, q_action)\n",
    "            \n",
    "            #if self.debugcounter % 20 == 0:\n",
    "            #    print(self.debugcounter)\n",
    "            #    print(updated_q_values)\n",
    "            #    print(rewards_sample)\n",
    "            #    print(q_action)\n",
    "            #self.debugcounter += 1\n",
    "\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "        \n",
    "    def get_X(self, batch, state):\n",
    "        \n",
    "        assert state == 0 or state == 3 # 0 is currentstate, 3 is future state\n",
    "        \n",
    "        X = [item[state] for item in batch]\n",
    "\n",
    "        X = np.array(X, dtype=np.float32)\n",
    "        \n",
    "        #for im in X:\n",
    "        #    assert im.min() == 0.0\n",
    "        #    assert im.max() == 255.0 or im.max() == 0.0\n",
    "        \n",
    "        X /= 255.0\n",
    "        \n",
    "        return X\n",
    "\n",
    "    def pop_batch(self, batchsize):\n",
    "       \n",
    "        batch = []\n",
    "        files = []\n",
    "    \n",
    "        for i in range(batchsize):\n",
    "            \n",
    "            item = self.shufflelist.pop(0)\n",
    "            \n",
    "            assert os.path.isfile(os.path.join(self.path, item[0]))\n",
    "            assert os.path.isfile(os.path.join(self.path, item[3]))\n",
    "            img1 = cv2.imread(os.path.join(self.path, item[0]),cv2.IMREAD_COLOR )\n",
    "            img2 = cv2.imread(os.path.join(self.path, item[3]),cv2.IMREAD_COLOR )\n",
    "\n",
    "            batch.append([img1, item[1], item[2], img2, item[4]])\n",
    "            files.append((item[0],item[3]))\n",
    "\n",
    "        return batch, files\n",
    "\n",
    "    def push_batch(self, batch, files):\n",
    "       \n",
    "        for index,item in enumerate(batch):\n",
    "            assert item[0].shape == (dim[0], dim[1], 3)\n",
    "            assert (item[1] < len(numtoactions) and item[1] >= 0)\n",
    "            assert isinstance(item[2],int) or isinstance(item[2],float)\n",
    "            assert item[3].shape == (dim[0], dim[1], 3)\n",
    "            assert os.path.isfile(os.path.join(self.path, files[index][0]))\n",
    "            assert os.path.isfile(os.path.join(self.path, files[index][1]))\n",
    "            \n",
    "            self.shufflelist.append([files[index][0], item[1], item[2], files[index][1], item[4]])\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def get_maxi(self):\n",
    "        \n",
    "        maxi = 0\n",
    "        \n",
    "        for item in self.shufflelist:\n",
    "            curr = item[0]\n",
    "            s = re.findall(r'\\d+', curr)[0]\n",
    "            if int(s) > maxi:\n",
    "                maxi = int(s)\n",
    "        \n",
    "        return maxi\n",
    "    \n",
    "    def load_replay_memory(self):\n",
    "\n",
    "        f = open(os.path.join(os.path.join(self.path,datacsvname)), \"r\")\n",
    "        \n",
    "        df = pd.read_csv(f, index_col = 0) \n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "\n",
    "            currentpicname = row[\"currentstate\"]\n",
    "            action = actionstonum[row[\"action\"]]\n",
    "            reward = row[\"reward\"]\n",
    "            nextpicname = row[\"nextstate\"]\n",
    "            terminated = row[\"terminated\"]\n",
    "\n",
    "            assert os.path.isfile(os.path.join(self.path,currentpicname)) == True\n",
    "            assert (action < 5 and action >= 0)\n",
    "            assert isinstance(reward,int) or isinstance(reward, float)\n",
    "            assert os.path.isfile(os.path.join(self.path,nextpicname)) == True\n",
    "            \n",
    "            self.shufflelist.append([currentpicname,action,reward,nextpicname, terminated])\n",
    "\n",
    "        random.shuffle(self.shufflelist)\n",
    "        \n",
    "        #print(self.shufflelist)\n",
    "\n",
    "        print(f\"loading: size of replay memory {len(self.shufflelist)}\")\n",
    "        \n",
    "        f.close()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def save_replay_memory(self):\n",
    "        \n",
    "        assert os.path.isfile(os.path.join(self.path,datacsvname)) == True\n",
    "        \n",
    "        data = []\n",
    "        \n",
    "        \n",
    "        if len(self.shufflelist) == 0:\n",
    "            return\n",
    "        \n",
    "        if len(self.shufflelist) > self.REPLAYSIZE:\n",
    "            \n",
    "            self.numbatches = len(self.shufflelist) - self.REPLAYSIZE\n",
    "            self.overall_numbatches += self.numbatches\n",
    "            \n",
    "            for i in range(len(self.shufflelist) - self.REPLAYSIZE):\n",
    "                item = self.shufflelist.pop(0)\n",
    "                assert os.path.isfile(os.path.join(self.path,item[0])) == True\n",
    "                assert os.path.isfile(os.path.join(self.path,item[3])) == True\n",
    "                \n",
    "                os.remove(os.path.join(self.path,item[0]))\n",
    "                os.remove(os.path.join(self.path,item[3]))\n",
    "                \n",
    "        for (cs, act, rew, fs, term) in self.shufflelist:\n",
    "            \n",
    "            data.append({'currentstate': cs, 'action': numtoactions[act], 'reward': rew, 'nextstate': fs, 'terminated': term})\n",
    "            \n",
    "        df = pd.DataFrame(data) \n",
    "        \n",
    "        df.to_csv(os.path.join(self.path, self.filename)) \n",
    "        \n",
    "        print(f\"saving: size of replay memory {len(self.shufflelist)}\")\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def print_benchmark(self):\n",
    "\n",
    "        maxlist = []\n",
    "        penaltylist = []\n",
    "        averagestates = [0,0,0]\n",
    "        averagepenalty = [0,0,0]\n",
    "        pmerror = 0\n",
    "        pterror = 0\n",
    "\n",
    "        for (cs, act, rew, fs, term) in self.shufflelist:\n",
    "            if rew >= 1:\n",
    "                maxlist.append((cs,act,rew,fs,term))\n",
    "            if rew <= self.PENALTY:\n",
    "                penaltylist.append((cs,act,rew,fs,term))\n",
    "        print(f\"Number of maxrewards in shufflelist: {len(maxlist)}, perc: {100*len(maxlist)/len(self.shufflelist)}\")\n",
    "        print(f\"Number of terminations in shufflelist: {len(penaltylist)}, perc: {100*len(penaltylist)/len(self.shufflelist)}\")\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        print(\"Testing maxlist\")\n",
    "        for i in range(len(maxlist)):\n",
    "            img = cv2.imread(os.path.join(pathname, datadirname, maxlist[i][0]),cv2.IMREAD_COLOR )\n",
    "            states = self.model.predict(np.array([img])/255.0, batch_size=1, verbose=0)[0]\n",
    "            averagestates += states\n",
    "            if np.argmax(states) != maxlist[i][1]:\n",
    "                count += 1\n",
    "            pmerror = 100*count/len(maxlist)\n",
    "        print(f\"Number of predicted errors in maxlist: {count}, perc: {pmerror}\")\n",
    "        print(f\"Q Values for max: {[i/len(maxlist) for i in averagestates]}\")\n",
    "        print(\"score: \" + str(self.scores))\n",
    "        print(\"average score: \" + str(statistics.mean(self.scores)))\n",
    "        overallscores.append(statistics.mean(self.scores))\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        print(\"Testing penaltylist\") \n",
    "        for i in range(len(penaltylist)):\n",
    "            img = cv2.imread(os.path.join(pathname, datadirname, penaltylist[i][0]),cv2.IMREAD_COLOR )\n",
    "            states = self.model.predict(np.array([img])/255.0, batch_size=1, verbose=0)[0]\n",
    "            averagepenalty += states\n",
    "            if np.argmax(states) == penaltylist[i][1]:\n",
    "                count += 1\n",
    "            pterror = 100*count/len(penaltylist)\n",
    "        print(f\"Number of predicted terminations in penaltylist: {count}, perc: {pterror}\")\n",
    "        print(f\"Q Values for penalty: {[i/len(penaltylist) for i in averagepenalty]}\")\n",
    "        \n",
    "        return pmerror, [i/len(maxlist) for i in averagestates], [i/len(penaltylist) for i in averagepenalty]\n",
    "    \n",
    "    def save_checkpoint(self, checkpointparname=modelweightname):\n",
    "                                                                         \n",
    "        self.model_target.set_weights(self.model.get_weights())\n",
    "        print(f\"saving checkpoint: {os.path.join(pathname, modeldirname,checkpointparname)}\")\n",
    "        self.model_target.save_weights(os.path.join(pathname, modeldirname,checkpointparname) )\n",
    "            \n",
    "        return\n",
    "\n",
    "    def print_score(self):\n",
    "        print(f\" ----> TIME IS {datetime.now():%Y-%m-%d_%H-%M-%S}\")\n",
    "        print(f\" ----> SCORE is {self.score}\")\n",
    "        print(f\" ----> NUM OF BATCHES is {self.numbatches}\")\n",
    "        return self.score, self.numbatches\n",
    "    \n",
    "    def print_overall_score(self):\n",
    "        print(f\"--> TIME IS {datetime.now():%Y-%m-%d_%H-%M-%S}\")\n",
    "        print(f\"--> OVERALL SCORE is {self.overall_score}\")\n",
    "        print(f\"--> OVERALL NUM OF BATCHES is {self.overall_numbatches}\")\n",
    "        return self.overall_score, self.overall_numbatches     \n",
    "    \n",
    "\n",
    "\n",
    "class Alien:\n",
    "    def __init__(self, game, x, y):\n",
    "        self.x = x\n",
    "        self.game = game\n",
    "        self.y = y\n",
    "        self.size = 40\n",
    "        self.will_be_hit = False\n",
    "\n",
    "    def draw(self):\n",
    "        pygame.draw.rect(self.game.screen,(0, 0, 255),  # barva objektu\n",
    "                         pygame.Rect(self.x, self.y, self.size, self.size))\n",
    "        self.y += 1.8\n",
    "\n",
    "    def checkCollision(self, game):\n",
    "        for rocket in game.rockets:\n",
    "            if (rocket.x < self.x + self.size and rocket.x + rocket.size > self.x and rocket.y < self.y + self.size and rocket.y > self.y - self.size):\n",
    "                game.rockets.remove(rocket)\n",
    "                game.aliens.remove(self)\n",
    "\n",
    "\n",
    "class Hero:\n",
    "    def __init__(self, game, x, y):\n",
    "        self.x = x\n",
    "        self.game = game\n",
    "        self.y = y\n",
    "\n",
    "    def draw(self):\n",
    "        pygame.draw.rect(self.game.screen,\n",
    "                         (255, 255, 255),\n",
    "                         pygame.Rect(self.x, self.y, 40, 20))\n",
    "\n",
    "\n",
    "class Rocket:\n",
    "    def __init__(self, game, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.game = game\n",
    "        self.size = 15\n",
    "\n",
    "    def draw(self):\n",
    "        pygame.draw.rect(self.game.screen,(0, 255, 0),pygame.Rect(self.x, self.y, self.size, self.size))\n",
    "        self.y -= 9 \n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    " #   game = Game(500, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: learning rate: 0.1\n",
      "60.0\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "loading: size of replay memory 3969\n",
      "Number of maxrewards in shufflelist: 636, perc: 15.493300852618757\n",
      "Number of terminations in shufflelist: 93, perc: 2.2655298416565164\n",
      "Testing maxlist\n",
      "Number of predicted errors in maxlist: 636, perc: 100.0\n",
      "Q Values for max: [0.0055191233994310385, 0.10548340819143462, -0.8687606044347931]\n",
      "score: [15, 16, 9]\n",
      "average score: 13.333333333333334\n",
      "Testing penaltylist\n",
      "Number of predicted terminations in penaltylist: 41, perc: 44.086021505376344\n",
      "Q Values for penalty: [-0.007155227735238049, 0.08774349333778504, -1.2871161494203793]\n",
      "saving: size of replay memory 4105\n",
      "saving checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr_0_0.100000000_100.00.h5\n",
      "1: learning rate: 0.1\n",
      "60.0\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "loading: size of replay memory 4105\n",
      "Number of maxrewards in shufflelist: 659, perc: 15.616113744075829\n",
      "Number of terminations in shufflelist: 96, perc: 2.2748815165876777\n",
      "Testing maxlist\n",
      "Number of predicted errors in maxlist: 623, perc: 94.53717754172989\n",
      "Q Values for max: [-0.06306827502545642, -0.021282560456147043, -0.7264892089227285]\n",
      "score: [10, 15, 20]\n",
      "average score: 15\n",
      "Testing penaltylist\n",
      "Number of predicted terminations in penaltylist: 44, perc: 45.833333333333336\n",
      "Q Values for penalty: [-0.1703413052794834, -0.0809870792242388, -1.4600686803460121]\n",
      "saving: size of replay memory 4220\n",
      "saving checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr_1_0.100000000_94.54.h5\n",
      "2: learning rate: 0.1\n",
      "60.0\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "loading: size of replay memory 4220\n",
      "Number of maxrewards in shufflelist: 674, perc: 15.562225813899792\n",
      "Number of terminations in shufflelist: 99, perc: 2.2858462248903257\n",
      "Testing maxlist\n",
      "Number of predicted errors in maxlist: 674, perc: 100.0\n",
      "Q Values for max: [0.07613336188215707, 0.020605255281746122, -0.6656883029759108]\n",
      "score: [13, 11, 10]\n",
      "average score: 11.333333333333334\n",
      "Testing penaltylist\n",
      "Number of predicted terminations in penaltylist: 45, perc: 45.45454545454545\n",
      "Q Values for penalty: [0.05969293502093566, -0.011169987613090663, -1.0105740391846858]\n",
      "saving: size of replay memory 4331\n",
      "saving checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr_2_0.100000000_100.00.h5\n",
      "3: learning rate: 0.05\n",
      "60.0\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "loading: size of replay memory 4331\n",
      "Number of maxrewards in shufflelist: 698, perc: 15.685393258426966\n",
      "Number of terminations in shufflelist: 102, perc: 2.292134831460674\n",
      "Testing maxlist\n",
      "Number of predicted errors in maxlist: 698, perc: 100.0\n",
      "Q Values for max: [0.08083557435591575, 0.09510347597236961, -0.541059666577417]\n",
      "score: [14, 11, 13]\n",
      "average score: 12.666666666666666\n",
      "Testing penaltylist\n",
      "Number of predicted terminations in penaltylist: 49, perc: 48.03921568627451\n",
      "Q Values for penalty: [0.03696498796161191, 0.03863573645460693, -0.9422966276898104]\n",
      "saving: size of replay memory 4450\n",
      "saving checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr_3_0.050000000_100.00.h5\n",
      "4: learning rate: 0.05\n",
      "60.0\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "loading: size of replay memory 4450\n",
      "Number of maxrewards in shufflelist: 722, perc: 15.757311217808818\n",
      "Number of terminations in shufflelist: 105, perc: 2.291575731121781\n",
      "Testing maxlist\n",
      "Number of predicted errors in maxlist: 722, perc: 100.0\n",
      "Q Values for max: [0.052424828002391864, -0.13997316373243845, -1.6501754556377508]\n",
      "score: [11, 13, 14]\n",
      "average score: 12.666666666666666\n",
      "Testing penaltylist\n",
      "Number of predicted terminations in penaltylist: 50, perc: 47.61904761904762\n",
      "Q Values for penalty: [-0.0013757269685378388, -0.23760806222756703, -2.292948663802374]\n",
      "saving: size of replay memory 4582\n",
      "saving checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr_4_0.050000000_100.00.h5\n",
      "Scores:  [13.333333333333334, 15, 11.333333333333334, 12.666666666666666, 12.666666666666666]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([100.0, 94.53717754172989, 100.0, 100.0, 100.0],\n",
       " [[0.0055191233994310385, 0.10548340819143462, -0.8687606044347931],\n",
       "  [-0.06306827502545642, -0.021282560456147043, -0.7264892089227285],\n",
       "  [0.07613336188215707, 0.020605255281746122, -0.6656883029759108],\n",
       "  [0.08083557435591575, 0.09510347597236961, -0.541059666577417],\n",
       "  [0.052424828002391864, -0.13997316373243845, -1.6501754556377508]],\n",
       " [[-0.007155227735238049, 0.08774349333778504, -1.2871161494203793],\n",
       "  [-0.1703413052794834, -0.0809870792242388, -1.4600686803460121],\n",
       "  [0.05969293502093566, -0.011169987613090663, -1.0105740391846858],\n",
       "  [0.03696498796161191, 0.03863573645460693, -0.9422966276898104],\n",
       "  [-0.0013757269685378388, -0.23760806222756703, -2.292948663802374]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_game(0.1, 5, 60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [9.166666666666666, 10, 10.066666666666666, 11.466666666666667, 11.133333333333333, 11.4, 10.266666666666667, 10.7, 11.166666666666666, 10.866666666666667, 12.3, 12.4, 11.6, 11.2, 11.333333333333334, 10.733333333333333, 12.166666666666666, 12.4, 10.9, 11.766666666666667, 10.8, 11.666666666666666, 11.666666666666666, 10.966666666666667, 11.9, 10.933333333333334, 10.733333333333333, 11.5, 12.2, 12.833333333333334, 13.8, 13.266666666666667, 12.366666666666667, 13.1, 12.4, 12.133333333333333, 13.6, 13.133333333333333, 13.3, 13.033333333333333, 13.433333333333334, 13.3, 12.333333333333334, 12.4, 12.766666666666667, 13.333333333333334, 13.233333333333333, 13.166666666666666, 13.066666666666666, 12.233333333333333, 13, 13.033333333333333, 13.5, 13.3, 11.933333333333334, 13.533333333333333, 12.3, 13.1, 12.3, 13.433333333333334]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22b2dc299c8>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(len(overallscores))\n",
    "plt.plot(x,overallscores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
