{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os.path\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, Flatten, ZeroPadding2D, UpSampling2D\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import pandas as pd \n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from scipy.signal import savgol_filter\n",
    "import math\n",
    "import time\n",
    "import statistics\n",
    "from os import listdir\n",
    "from shutil import copyfile\n",
    "\n",
    "pathname = r\"D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\"\n",
    "datadirname = \"data_new\"\n",
    "testdirname = \"test\"\n",
    "validdirname = \"valid\"\n",
    "modeldirname = \"model\"\n",
    "datacsvname = \"data.csv\"\n",
    "modeljsonname=\"model-regr.json\"\n",
    "modelweightname=\"model-regr.h5\"\n",
    "dim = (50,50) \n",
    "actionstonum = {\"RIGHT\": 0,\n",
    "           \"LEFT\": 1,\n",
    "           \"SPACE\" : 2,\n",
    "          }\n",
    "numtoactions = {0: \"RIGHT\",\n",
    "           1: \"LEFT\",\n",
    "           2: \"SPACE\",\n",
    "          }\n",
    "scores = []\n",
    "overallscores = []\n",
    "manual = False\n",
    "modulo_counter = 3\n",
    "\n",
    "\n",
    "def create_q_model():\n",
    "        # Network defined by the Deepmind paper\n",
    "        inputs = layers.Input(shape=(dim[0], dim[1], 3,))\n",
    "\n",
    "        # Convolutions on the frames on the screen\n",
    "        layer1 = layers.Conv2D(32, 8, strides=4, activation=\"relu\")(inputs)\n",
    "        layer2 = layers.Conv2D(64, 4, strides=2, activation=\"relu\")(layer1)\n",
    "        layer3 = layers.Conv2D(64, 3, strides=1, activation=\"relu\")(layer2)\n",
    "\n",
    "        layer4 = layers.Flatten()(layer3)\n",
    "\n",
    "        layer5 = layers.Dense(512, activation=\"relu\")(layer4)\n",
    "        action = layers.Dense(3, activation=\"linear\")(layer5)\n",
    "\n",
    "        return keras.Model(inputs=inputs, outputs=action)\n",
    "\n",
    "def run_game(learning_rate = 1.5e-06, epochs = 5, benchmin = 15):\n",
    "    lr = [learning_rate for i in range(epochs)]\n",
    "\n",
    "    iterations = len(lr)\n",
    "    benches = []\n",
    "    qms = []\n",
    "    qps = []\n",
    "    counter = 0\n",
    "    epsilon = 0.25\n",
    "    global modulo_counter\n",
    "\n",
    "    for i in range(iterations):\n",
    "        print(f\"{i}: learning rate: {lr[i]}\")\n",
    "        print(benchmin)\n",
    "        k = 50\n",
    "        game = Game(500,500, epsilon)\n",
    "        epsilon *= 0.9\n",
    "        game.load_replay_memory()\n",
    "        for j in range(k):\n",
    "            game.initialize()\n",
    "            game.run(j)\n",
    "        bench, qm, qp, score = game.print_benchmark()\n",
    "        benches.append(bench)\n",
    "        qms.append(qm)\n",
    "        qps.append(qp)\n",
    "        game.save_replay_memory()\n",
    "        game.save_checkpoint(f\"model-regr_{i}_{lr[i]:.9f}_{bench:.2f}_{score:.2f}.h5\")\n",
    "        game.load_checkpoint()\n",
    "        if score < benchmin:\n",
    "            benchmin = score\n",
    "            game.save_checkpoint()\n",
    "            modulo_counter += 1\n",
    "            #lr = [i*0.5 for i in lr] \n",
    "        else:\n",
    "            counter += 1\n",
    "        if counter == 3 and lr[i] > 1e-6:\n",
    "            counter = 0\n",
    "            lr = [i*0.5 for i in lr] \n",
    "            \n",
    "    print(\"Scores: \", overallscores)\n",
    "\n",
    "    return benches, qms, qps\n",
    "\n",
    "model = create_q_model()\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(pathname, modeldirname,modeljsonname), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(os.path.join(pathname, modeldirname,modelweightname))\n",
    "\n",
    "\n",
    "class Game:\n",
    "    screen = None\n",
    "    \n",
    "    lost = False\n",
    "    done = False\n",
    "\n",
    "    def __init__(self, width, height, epsilon, lr=1e-3, checkpointparname=\"model-regr.h5\"):\n",
    "        \n",
    "        self.currentAction = \"\"\n",
    "                       \n",
    "        self.shufflelist = []\n",
    "        \n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.screen = pygame.display.set_mode((int(width), int(height)))\n",
    "        self.screen.fill([255,0,0])\n",
    "\n",
    "        self.imgresh1 = None\n",
    "        self.imgresh2 = None\n",
    "\n",
    "        self.reward = 0\n",
    "        self.MAXREWARD = 5\n",
    "        self.HITREWARD = 2\n",
    "        self.PENALTY = -4\n",
    "        self.FIREPENALTY = -1 \n",
    "        self.MOVEPENALTY = 0\n",
    "        self.NOTFIREPENALTY = -2\n",
    "        \n",
    "        self.BATCHSIZE = 19\n",
    "        self.DISCOUNT = 0.99\n",
    "        self.ALPHA = 0.3\n",
    "        \n",
    "        \n",
    "        self.EPSILON = epsilon\n",
    "        \n",
    "        self.ALIENPROB = 0.4\n",
    "        \n",
    "        self.REPLAYSIZE = 40_000\n",
    "        self.overall_score = 0\n",
    "        self.overall_numbatches = 0\n",
    "        self.overall_accumulatedstates = np.array([0.0,0.0,0.0,0.0])\n",
    "        \n",
    "        self.scores = []\n",
    "        \n",
    "        \n",
    "        self.path = os.path.join(pathname, datadirname)\n",
    "        self.modelpath =  os.path.join(pathname, modeldirname)\n",
    "        \n",
    "        self.filename = \"data.csv\"\n",
    "        \n",
    "        self.model = create_q_model()\n",
    "        self.model_target = create_q_model()\n",
    "\n",
    "        self.learningrate = lr\n",
    "        self.optimizer = keras.optimizers.Adam(learning_rate=self.learningrate, clipnorm=1.0)\n",
    "        self.loss_function = keras.losses.Huber()\n",
    "\n",
    "        self.checkpointname = os.path.join(pathname, modeldirname,checkpointparname)\n",
    "        print(f\"loading checkpoint: {self.checkpointname}\")\n",
    "        self.model_target.load_weights(self.checkpointname)\n",
    "        \n",
    "        self.overall_scores=[]\n",
    "        self.checkpoint_counter=0\n",
    "        \n",
    "        self.debugcounter = 0\n",
    "        \n",
    "        self.counter_alien_center = 0\n",
    "\n",
    "        \n",
    "    def initialize(self):\n",
    "        pygame.init()\n",
    "        self.aliens = []\n",
    "        self.rockets = []\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.hero = Hero(self, self.width / 2, self.height - 20)\n",
    "        self.firstFire = True\n",
    "        \n",
    "        #Generator\n",
    "        margin = 30  # mezera od okraju obrazovky\n",
    "        width = 50  # mezera mezi alieny\n",
    "        self.screen = pygame.display.set_mode((int(self.width), int(self.height)))\n",
    "        for x in range(margin, self.width - margin, width):\n",
    "            for y in range(margin, int(self.height / 2), width):\n",
    "                if(random.random()<=self.ALIENPROB):\n",
    "                    self.aliens.append(Alien(self, x, y))\n",
    "                    \n",
    "        self.rocket = None\n",
    "        self.numbatches = 0\n",
    "        \n",
    "        self.model.load_weights(self.checkpointname)\n",
    "        \n",
    "        self.counter_alien_center = 0\n",
    "    \n",
    "\n",
    "    def run(self, i_index):\n",
    "        i = i_index + self.get_maxi() + 1\n",
    "        j = 0\n",
    "        while True:\n",
    "            img1 = np.frombuffer(pygame.image.tostring(self.screen, \"RGB\"), dtype=np.uint8)\n",
    "            self.imgresh1 = np.reshape(img1,(self.width,self.height, 3))\n",
    "            self.imgresh1 = cv2.resize(self.imgresh1, dim, interpolation = cv2.INTER_NEAREST )\n",
    "            self.imgresh1 = cv2.cvtColor(self.imgresh1, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            current_state = np.array(self.imgresh1, dtype=np.float32)/255.0\n",
    "            state_tensor = tf.convert_to_tensor(current_state)\n",
    "            state_tensor = tf.expand_dims(state_tensor, 0)\n",
    "            action_probs = self.model(state_tensor, training=False)\n",
    "            theaction = tf.argmax(action_probs[0]).numpy()            \n",
    "\n",
    "            #win\n",
    "            if len(self.aliens) == 0:\n",
    "                pygame.display.flip()                         \n",
    "                pygame.quit()\n",
    "                return\n",
    "\n",
    "            pressed = pygame.key.get_pressed()\n",
    "            if pressed[pygame.K_LEFT]:\n",
    "                self.currentAction = \"LEFT\"\n",
    "                \n",
    "            elif pressed[pygame.K_RIGHT]:\n",
    "                self.currentAction = \"RIGHT\"\n",
    "                \n",
    "            elif pressed[pygame.K_q]:\n",
    "                pygame.display.flip()                         \n",
    "                pygame.quit()\n",
    "                return\n",
    "\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.KEYDOWN and event.key == pygame.K_SPACE and not self.lost:\n",
    "                    self.currentAction = \"SPACE\"\n",
    "                \n",
    "            #if manual != True:\n",
    "            #    if np.random.random() > self.EPSILON:\n",
    "            #        self.currentAction = numtoactions[theaction]\n",
    "            #    else:\n",
    "            #        self.currentAction = numtoactions[random.randint(0,2)]\n",
    "            self.currentAction = numtoactions[random.randint(0,2)]\n",
    "            \n",
    "            if self.counter_alien_center % modulo_counter == 0:\n",
    "                alien_sort = sorted([(alien.y,alien.x) for alien in self.aliens])[::-1]\n",
    "                alien_max = []\n",
    "                for i in range(len(alien_sort)):\n",
    "                    if alien_sort[i][0] == alien_sort[0][0]:\n",
    "                        alien_max.append(alien_sort[i])\n",
    "                    else:\n",
    "                        break\n",
    "                alien_next = min([(abs(self.hero.x - alien[1]),alien[1]) for alien in alien_max])\n",
    "                if alien_next[1] > self.hero.x:\n",
    "                    self.currentAction = \"RIGHT\"\n",
    "                elif alien_next[1] < self.hero.x:\n",
    "                    self.currentAction = \"LEFT\"\n",
    "                self.counter_alien_center = 0\n",
    "                \n",
    "            \n",
    "            self.counter_alien_center += 1\n",
    "                \n",
    "                \n",
    "            if self.currentAction == \"RIGHT\":\n",
    "                self.hero.x += 6 if self.hero.x < self.width - 20 else 0  # prava hranice\n",
    "                self.reward = self.MOVEPENALTY\n",
    "                \n",
    "            if self.currentAction == \"LEFT\":\n",
    "                self.hero.x -= 6 if self.hero.x > 20 else 0  # leva hranice plochy\n",
    "                self.reward = self.MOVEPENALTY\n",
    "            \n",
    "            if len(self.rockets) == 0:\n",
    "                self.firstFire = True\n",
    "            \n",
    "            if self.currentAction == \"SPACE\":\n",
    "                if self.firstFire or self.rockets[-1].y + self.rockets[-1].size < self.hero.y:\n",
    "                    self.rockets.append(Rocket(self, self.hero.x, self.hero.y))\n",
    "                    if self.checkHit(self.rockets[-1]):\n",
    "                        self.reward = self.HITREWARD\n",
    "                    else:\n",
    "                        self.reward = self.FIREPENALTY\n",
    "                else:\n",
    "                    reward = self.NOTFIREPENALTY\n",
    "                self.firstFire = False\n",
    "            \n",
    "            if manual == True:\n",
    "                self.currentAction = \"LEFT\"\n",
    "\n",
    "            pygame.display.flip()\n",
    "            self.clock.tick(60)\n",
    "            self.screen.fill((255, 0, 0))\n",
    "            \n",
    "            img2 = np.frombuffer(pygame.image.tostring(self.screen, \"RGB\"), dtype=np.uint8)\n",
    "            self.imgresh2 = np.reshape(img2,(self.width,self.height, 3))\n",
    "            self.imgresh2 = cv2.resize(img2, dim, interpolation = cv2.INTER_NEAREST )\n",
    "            self.imgresh2 = cv2.cvtColor(self.imgresh2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            for alien in self.aliens:\n",
    "                alien.draw()\n",
    "                alien.checkCollision(self)\n",
    "                if (alien.y > (self.height-60)):\n",
    "                    self.reward = self.PENALTY\n",
    "                    self.train(i,j, True)\n",
    "                    self.scores.append(len(self.aliens))\n",
    "                    pygame.display.flip()                         \n",
    "                    pygame.quit()\n",
    "                    return\n",
    "                    \n",
    "            for rocket in self.rockets:\n",
    "                rocket.draw()\n",
    "\n",
    "            if not self.lost: self.hero.draw()\n",
    "                \n",
    "            \n",
    "            if j > 0:\n",
    "                if j%4 == 0:\n",
    "                    self.train(i,j, False)\n",
    "\n",
    "            j+=1\n",
    "\n",
    "    def checkHit(self, rocket):\n",
    "        for alien in self.aliens:\n",
    "            if (rocket.x < alien.x + alien.size and \n",
    "                    rocket.x + rocket.size > alien.x and\n",
    "                    not alien.will_be_hit):\n",
    "                alien.will_be_hit = True\n",
    "                return True\n",
    "            \n",
    "            \n",
    "    def write(self, i, j): \n",
    "\n",
    "        cv2.imwrite(os.path.join(self.path,\"current_{}_{}.png\".format(i,j)), self.imgresh1)\n",
    "        cv2.imwrite(os.path.join(self.path,\"next_{}_{}.png\".format(i,j)), self.imgresh2)\n",
    "\n",
    "    def train(self, i, j, term):\n",
    "        \n",
    "        # https://pythonprogramming.net/training-deep-q-learning-dqn-reinforcement-learning-python-tutorial/\n",
    "        \n",
    "        currentstate = \"current_{}_{}.png\".format(i,j)\n",
    "\n",
    "        nextstate = \"next_{}_{}.png\".format(i,j)      \n",
    "        \n",
    "        batch, files = self.pop_batch(self.BATCHSIZE)\n",
    "        \n",
    "        assert(self.imgresh1.shape == (dim[0], dim[1],3))\n",
    "        assert(self.imgresh2.shape == (dim[0], dim[1],3))\n",
    "        \n",
    "        batch.append([self.imgresh1, actionstonum[self.currentAction], self.reward, self.imgresh2, term])\n",
    "        files.append((\"current_{}_{}.png\".format(i,j), \"next_{}_{}.png\".format(i,j)))\n",
    "        \n",
    "        self.write(i,j)\n",
    "         \n",
    "        self.backprop(batch)\n",
    "        \n",
    "        self.numbatches += 1\n",
    "            \n",
    "        self.push_batch(batch, files)   \n",
    "  \n",
    "        return    \n",
    "\n",
    "    def backprop(self, batch):\n",
    "\n",
    "        rewards_sample = [batch[i][2] for i in range(len(batch))]\n",
    "        action_sample = [batch[i][1] for i in range(len(batch))]\n",
    "      \n",
    "        done_sample = tf.convert_to_tensor([float(batch[i][4]) for i in range(len(batch))])\n",
    "\n",
    "        X =  self.get_X(batch, 0)\n",
    "        Xf = self.get_X(batch, 3)\n",
    "        future_rewards = self.model_target.predict(Xf)\n",
    "\n",
    "        updated_q_values = rewards_sample + 0.99 * tf.reduce_max(future_rewards, axis=1)\n",
    "        updated_q_values = updated_q_values * (1 - done_sample) - done_sample*abs(self.PENALTY)\n",
    "\n",
    "    \n",
    "        masks = tf.one_hot(action_sample, 3)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Train the model on the states and updated Q-values\n",
    "            q_values = self.model(X)\n",
    "\n",
    "            # Apply the masks to the Q-values to get the Q-value for action taken\n",
    "            q_action = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
    "            # Calculate loss between new Q-value and old Q-value\n",
    "            loss = self.loss_function(updated_q_values, q_action)\n",
    "            \n",
    "            #if self.debugcounter % 20 == 0:\n",
    "            #    print(self.debugcounter)\n",
    "            #    print(updated_q_values)\n",
    "            #    print(rewards_sample)\n",
    "            #    print(q_action)\n",
    "            #self.debugcounter += 1\n",
    "\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "        \n",
    "    def get_X(self, batch, state):\n",
    "        \n",
    "        assert state == 0 or state == 3 # 0 is currentstate, 3 is future state\n",
    "        \n",
    "        X = [item[state] for item in batch]\n",
    "\n",
    "        X = np.array(X, dtype=np.float32)\n",
    "        \n",
    "        #for im in X:\n",
    "        #    assert im.min() == 0.0\n",
    "        #    assert im.max() == 255.0 or im.max() == 0.0\n",
    "        \n",
    "        X /= 255.0\n",
    "        \n",
    "        return X\n",
    "\n",
    "    def pop_batch(self, batchsize):\n",
    "       \n",
    "        batch = []\n",
    "        files = []\n",
    "    \n",
    "        for i in range(batchsize):\n",
    "            \n",
    "            item = self.shufflelist.pop(0)\n",
    "            \n",
    "            assert os.path.isfile(os.path.join(self.path, item[0]))\n",
    "            assert os.path.isfile(os.path.join(self.path, item[3]))\n",
    "            img1 = cv2.imread(os.path.join(self.path, item[0]),cv2.IMREAD_COLOR )\n",
    "            img2 = cv2.imread(os.path.join(self.path, item[3]),cv2.IMREAD_COLOR )\n",
    "\n",
    "            batch.append([img1, item[1], item[2], img2, item[4]])\n",
    "            files.append((item[0],item[3]))\n",
    "\n",
    "        return batch, files\n",
    "\n",
    "    def push_batch(self, batch, files):\n",
    "       \n",
    "        for index,item in enumerate(batch):\n",
    "            assert item[0].shape == (dim[0], dim[1], 3)\n",
    "            assert (item[1] < len(numtoactions) and item[1] >= 0)\n",
    "            assert isinstance(item[2],int) or isinstance(item[2],float)\n",
    "            assert item[3].shape == (dim[0], dim[1], 3)\n",
    "            assert os.path.isfile(os.path.join(self.path, files[index][0]))\n",
    "            assert os.path.isfile(os.path.join(self.path, files[index][1]))\n",
    "            \n",
    "            self.shufflelist.append([files[index][0], item[1], item[2], files[index][1], item[4]])\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def get_maxi(self):\n",
    "        \n",
    "        maxi = 0\n",
    "        \n",
    "        for item in self.shufflelist:\n",
    "            curr = item[0]\n",
    "            s = re.findall(r'\\d+', curr)[0]\n",
    "            if int(s) > maxi:\n",
    "                maxi = int(s)\n",
    "        \n",
    "        return maxi\n",
    "    \n",
    "    def load_replay_memory(self):\n",
    "\n",
    "        f = open(os.path.join(os.path.join(self.path,datacsvname)), \"r\")\n",
    "        \n",
    "        df = pd.read_csv(f, index_col = 0) \n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "\n",
    "            currentpicname = row[\"currentstate\"]\n",
    "            action = actionstonum[row[\"action\"]]\n",
    "            reward = row[\"reward\"]\n",
    "            nextpicname = row[\"nextstate\"]\n",
    "            terminated = row[\"terminated\"]\n",
    "\n",
    "            assert os.path.isfile(os.path.join(self.path,currentpicname)) == True\n",
    "            assert (action < 5 and action >= 0)\n",
    "            assert isinstance(reward,int) or isinstance(reward, float)\n",
    "            assert os.path.isfile(os.path.join(self.path,nextpicname)) == True\n",
    "            \n",
    "            self.shufflelist.append([currentpicname,action,reward,nextpicname, terminated])\n",
    "\n",
    "        random.shuffle(self.shufflelist)\n",
    "        \n",
    "        #print(self.shufflelist)\n",
    "\n",
    "        print(f\"loading: size of replay memory {len(self.shufflelist)}\")\n",
    "        \n",
    "        f.close()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def save_replay_memory(self):\n",
    "        \n",
    "        assert os.path.isfile(os.path.join(self.path,datacsvname)) == True\n",
    "        \n",
    "        data = []\n",
    "        \n",
    "        \n",
    "        if len(self.shufflelist) == 0:\n",
    "            return\n",
    "        \n",
    "        if len(self.shufflelist) > self.REPLAYSIZE:\n",
    "            \n",
    "            self.numbatches = len(self.shufflelist) - self.REPLAYSIZE\n",
    "            self.overall_numbatches += self.numbatches\n",
    "            \n",
    "            for i in range(len(self.shufflelist) - self.REPLAYSIZE):\n",
    "                item = self.shufflelist.pop(0)\n",
    "                assert os.path.isfile(os.path.join(self.path,item[0])) == True\n",
    "                assert os.path.isfile(os.path.join(self.path,item[3])) == True\n",
    "                \n",
    "                os.remove(os.path.join(self.path,item[0]))\n",
    "                os.remove(os.path.join(self.path,item[3]))\n",
    "                \n",
    "        for (cs, act, rew, fs, term) in self.shufflelist:\n",
    "            \n",
    "            data.append({'currentstate': cs, 'action': numtoactions[act], 'reward': rew, 'nextstate': fs, 'terminated': term})\n",
    "            \n",
    "        df = pd.DataFrame(data) \n",
    "        \n",
    "        df.to_csv(os.path.join(self.path, self.filename)) \n",
    "        \n",
    "        print(f\"saving: size of replay memory {len(self.shufflelist)}\")\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def print_benchmark(self):\n",
    "\n",
    "        maxlist = []\n",
    "        penaltylist = []\n",
    "        averagestates = [0,0,0]\n",
    "        averagepenalty = [0,0,0]\n",
    "        pmerror = 0\n",
    "        pterror = 0\n",
    "\n",
    "        for (cs, act, rew, fs, term) in self.shufflelist:\n",
    "            if rew >= 1:\n",
    "                maxlist.append((cs,act,rew,fs,term))\n",
    "            if rew <= self.PENALTY:\n",
    "                penaltylist.append((cs,act,rew,fs,term))\n",
    "        print(f\"Number of maxrewards in shufflelist: {len(maxlist)}, perc: {100*len(maxlist)/len(self.shufflelist)}\")\n",
    "        print(f\"Number of terminations in shufflelist: {len(penaltylist)}, perc: {100*len(penaltylist)/len(self.shufflelist)}\")\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        print(\"Testing maxlist\")\n",
    "        for i in range(len(maxlist)):\n",
    "            img = cv2.imread(os.path.join(pathname, datadirname, maxlist[i][0]),cv2.IMREAD_COLOR )\n",
    "            states = self.model.predict(np.array([img])/255.0, batch_size=1, verbose=0)[0]\n",
    "            averagestates += states\n",
    "            if np.argmax(states) != maxlist[i][1]:\n",
    "                count += 1\n",
    "            pmerror = 100*count/len(maxlist)\n",
    "        print(f\"Number of predicted errors in maxlist: {count}, perc: {pmerror}\")\n",
    "        print(f\"Q Values for max: {[i/len(maxlist) for i in averagestates]}\")\n",
    "        print(\"score: \" + str(self.scores))\n",
    "        average_score = statistics.mean(self.scores)\n",
    "        print(\"average score: \" + str(average_score))\n",
    "        overallscores.append(statistics.mean(self.scores))\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        print(\"Testing penaltylist\") \n",
    "        for i in range(len(penaltylist)):\n",
    "            img = cv2.imread(os.path.join(pathname, datadirname, penaltylist[i][0]),cv2.IMREAD_COLOR )\n",
    "            states = self.model.predict(np.array([img])/255.0, batch_size=1, verbose=0)[0]\n",
    "            averagepenalty += states\n",
    "            if np.argmax(states) == penaltylist[i][1]:\n",
    "                count += 1\n",
    "            pterror = 100*count/len(penaltylist)\n",
    "        print(f\"Number of predicted terminations in penaltylist: {count}, perc: {pterror}\")\n",
    "        print(f\"Q Values for penalty: {[i/len(penaltylist) for i in averagepenalty]}\")\n",
    "        \n",
    "        print(\"modulo counter\", modulo_counter)\n",
    "        return pmerror, [i/len(maxlist) for i in averagestates], [i/len(penaltylist) for i in averagepenalty], average_score\n",
    "    \n",
    "    def save_checkpoint(self, checkpointparname=modelweightname):\n",
    "                                                                         \n",
    "        self.model_target.set_weights(self.model.get_weights())\n",
    "        print(f\"saving checkpoint: {os.path.join(pathname, modeldirname,checkpointparname)}\")\n",
    "        self.model_target.save_weights(os.path.join(pathname, modeldirname,checkpointparname) )\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def load_checkpoint(self):\n",
    "        path = os.path.join(pathname, modeldirname)\n",
    "        checkpoint_files = [(f.split('_')[-1][:-3],f) for f in listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "        checkpoint_files_floats = []\n",
    "        for f in checkpoint_files:\n",
    "            try:\n",
    "                checkpoint_files_floats.append((float(f[0]),f[1]))\n",
    "            except ValueError:\n",
    "                None\n",
    "        checkpoint_path = os.path.join(pathname,modeldirname,min(checkpoint_files_floats)[1])\n",
    "        dest_path = os.path.join(pathname,modeldirname,modelweightname)\n",
    "        copyfile(checkpoint_path,dest_path)\n",
    "        \n",
    "\n",
    "    def print_score(self):\n",
    "        print(f\" ----> TIME IS {datetime.now():%Y-%m-%d_%H-%M-%S}\")\n",
    "        print(f\" ----> SCORE is {self.score}\")\n",
    "        print(f\" ----> NUM OF BATCHES is {self.numbatches}\")\n",
    "        return self.score, self.numbatches\n",
    "    \n",
    "    def print_overall_score(self):\n",
    "        print(f\"--> TIME IS {datetime.now():%Y-%m-%d_%H-%M-%S}\")\n",
    "        print(f\"--> OVERALL SCORE is {self.overall_score}\")\n",
    "        print(f\"--> OVERALL NUM OF BATCHES is {self.overall_numbatches}\")\n",
    "        return self.overall_score, self.overall_numbatches     \n",
    "    \n",
    "\n",
    "\n",
    "class Alien:\n",
    "    def __init__(self, game, x, y):\n",
    "        self.x = x\n",
    "        self.game = game\n",
    "        self.y = y\n",
    "        self.size = 40\n",
    "        self.will_be_hit = False\n",
    "\n",
    "    def draw(self):\n",
    "        pygame.draw.rect(self.game.screen,(0, 0, 255),  # barva objektu\n",
    "                         pygame.Rect(self.x, self.y, self.size, self.size))\n",
    "        self.y += 1.8\n",
    "\n",
    "    def checkCollision(self, game):\n",
    "        for rocket in game.rockets:\n",
    "            if (rocket.x < self.x + self.size and rocket.x + rocket.size > self.x and rocket.y < self.y + self.size and rocket.y > self.y - self.size):\n",
    "                game.rockets.remove(rocket)\n",
    "                game.aliens.remove(self)\n",
    "\n",
    "\n",
    "class Hero:\n",
    "    def __init__(self, game, x, y):\n",
    "        self.x = x\n",
    "        self.game = game\n",
    "        self.y = y\n",
    "\n",
    "    def draw(self):\n",
    "        pygame.draw.rect(self.game.screen,\n",
    "                         (255, 255, 255),\n",
    "                         pygame.Rect(self.x, self.y, 40, 20))\n",
    "\n",
    "\n",
    "class Rocket:\n",
    "    def __init__(self, game, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.game = game\n",
    "        self.size = 15\n",
    "\n",
    "    def draw(self):\n",
    "        pygame.draw.rect(self.game.screen,(0, 255, 0),pygame.Rect(self.x, self.y, self.size, self.size))\n",
    "        self.y -= 9 \n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    " #   game = Game(500, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: learning rate: 0.1\n",
      "60.0\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "loading: size of replay memory 3162\n",
      "Number of maxrewards in shufflelist: 57, perc: 1.7543859649122806\n",
      "Number of terminations in shufflelist: 99, perc: 3.0470914127423825\n",
      "Testing maxlist\n",
      "Number of predicted errors in maxlist: 57, perc: 100.0\n",
      "Q Values for max: [-0.004215265301530037, 0.041879256047602544, -0.429837311830437]\n",
      "score: [7, 10, 10]\n",
      "average score: 9\n",
      "Testing penaltylist\n",
      "Number of predicted terminations in penaltylist: 51, perc: 51.515151515151516\n",
      "Q Values for penalty: [-0.05639071021266658, -0.021519513717250464, -0.5088520230668964]\n",
      "modulo counter 3\n",
      "saving: size of replay memory 3249\n",
      "saving checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr_0_0.100000000_100.00_9.00.h5\n",
      "saving checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "1: learning rate: 0.1\n",
      "9\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "loading: size of replay memory 3249\n",
      "Number of maxrewards in shufflelist: 57, perc: 1.7076093469143199\n",
      "Number of terminations in shufflelist: 102, perc: 3.055721989215099\n",
      "Testing maxlist\n",
      "Number of predicted errors in maxlist: 57, perc: 100.0\n",
      "Q Values for max: [-0.005309150331620977, 0.03204767294064687, -0.22962087196739098]\n",
      "score: [8, 9, 7]\n",
      "average score: 8\n",
      "Testing penaltylist\n",
      "Number of predicted terminations in penaltylist: 51, perc: 50.0\n",
      "Q Values for penalty: [-0.1195941053550033, -0.053765480543541556, -0.3513552502674215]\n",
      "modulo counter 4\n",
      "saving: size of replay memory 3338\n",
      "saving checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr_1_0.100000000_100.00_8.00.h5\n",
      "saving checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "2: learning rate: 0.1\n",
      "8\n",
      "loading checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr.h5\n",
      "loading: size of replay memory 3338\n",
      "Number of maxrewards in shufflelist: 63, perc: 1.8356643356643356\n",
      "Number of terminations in shufflelist: 105, perc: 3.0594405594405596\n",
      "Testing maxlist\n",
      "Number of predicted errors in maxlist: 63, perc: 100.0\n",
      "Q Values for max: [-0.03408661973293102, -0.008163597471716385, -0.5645300729407204]\n",
      "score: [9, 13, 16]\n",
      "average score: 12.666666666666666\n",
      "Testing penaltylist\n",
      "Number of predicted terminations in penaltylist: 43, perc: 40.95238095238095\n",
      "Q Values for penalty: [-0.6516989720719201, -0.6705180525779724, -1.0638369270733425]\n",
      "modulo counter 5\n",
      "saving: size of replay memory 3432\n",
      "saving checkpoint: D:\\OneDrive - Hochschule Albstadt-Sigmaringen\\Studium\\Semester 5\\DesignCPS\\model\\model-regr_2_0.100000000_100.00_12.67.h5\n",
      "Scores:  [9, 8, 12.666666666666666]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([100.0, 100.0, 100.0],\n",
       " [[-0.004215265301530037, 0.041879256047602544, -0.429837311830437],\n",
       "  [-0.005309150331620977, 0.03204767294064687, -0.22962087196739098],\n",
       "  [-0.03408661973293102, -0.008163597471716385, -0.5645300729407204]],\n",
       " [[-0.05639071021266658, -0.021519513717250464, -0.5088520230668964],\n",
       "  [-0.1195941053550033, -0.053765480543541556, -0.3513552502674215],\n",
       "  [-0.6516989720719201, -0.6705180525779724, -1.0638369270733425]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_game(0.1, 100, 60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14b6e701908>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXiU5bn48e8zk33fSQjZCEvCvoRFqAjuotW6gVZttbVWbXvanva0PafLqee0v+49PXaz9hSxrSIq1rqhtYKigIQQgQQJBEjIvofs28w8vz8miQGSycxk1uT+XBeX4Z13ufMKdx7uZ1Naa4QQQvgfg7cDEEII4RxJ4EII4ackgQshhJ+SBC6EEH5KErgQQvipAE8+LCEhQWdmZnrykUII4fcOHTrUpLVOvPC4RxN4ZmYmBQUFnnykEEL4PaXU2dGOSwlFCCH8lCRwIYTwU5LAhRDCT0kCF0IIPyUJXAgh/JQkcCGE8FOSwIUQwk9JAhdC+JWdRbVUtXZ7OwyfIAlcCOE3ypu6eOipQv7wzhlvh+ITJIELIfzGswWVAJTUtXs5Et8gCVwI4RdMZgvPH6oCoKS2A9lNzI4ErpTaopRqUEoVjzi2RCn1vlLqsFKqQCm10r1hCiGmurdPNNLQ0cf6uYl09Jmoau3xdkheZ08LfCtw7QXHfgo8orVeAnxv8PdCCOE2zxysJDEymIfXzwKgpK7DyxF537gJXGu9B2i58DAQNfh1NFDj4riEEGJYfXsvu080cNvyGcyfbk09x2ulDu7scrJfAd5QSv0c6w+BNWOdqJR6AHgAID093cnHCSGmsucPVWG2aDblpREeHEBGfJh0ZOJ8J+ZDwFe11mnAV4E/jXWi1vpxrXWe1jovMfGi9ciFEMImrTXPFlSyKiuOrIRwAHKToyiplRKKswn808ALg18/B0gnphDCLd4/08LZ5m7uWJk2fCwnJZKy5i66+01ejMz7nE3gNcBlg19fDpS6JhwhhDjf9oMVRIYEcN2ClOFjOclRaA0n6zu9GJn3jVsDV0ptA9YDCUqpKuA/gc8B/6uUCgB6GaxxCyGEK7V1D7CzuI5NeWmEBBqHj89LsXZkltS2syQtxlvhed24CVxrfecYHy13cSxCCHGevx+pps9kYfOKtPOOz4gNJTzIOOVHoshMTCGET9Jasy2/kgWpUSxIjT7vM4NBMTc5kuNTfCy4JHAhhE8qrm7neG07m/PSRv08NyWKktr2KT2lXhK4EMInbS+oIDjAwI1LUkf9PCclivZeEzVtvR6OzHdIAhdC+JyefjN//6CG6xemEB0aOOo581IiAWtH5lQlCVwI4XNeK6qlo8/EphWjl08A5kyzJvCp3JEpCVwI4XO2F1SSGR/Gqqy4Mc+JDAkkLS50SndkSgIXQviUM42d5Je1sHlFOkopm+dap9RLC1wIIXzC9oJKjAbFrctH77wcKSclirKmLnoHzB6IzPdIAhdC+IwBs4Udh6q4PCeJpMiQcc+flxKJRcPJ+qlZRpEELoTwGbtKGmjq7OcOG52XI+UkD02pd20CN5kt7Cqp5z/+VkRFc7dL7+1Kzq4HLoQQLrf9YCVJkcFcNse+pafT48IICzLyoYvq4OVNXTxbUMmOwirq2/sA6B0w88tNS1xyf1eTBC6E8Al1bb28faKBh9ZnE2C0rzgwNKV+Ips79PSbea2olu0FleSXtWBQsH5uEo/cmMae0kaeL6ji36/LJTEy2OlnuIskcCGET3j+UCUWDZvGmDo/lpzkKHYW16K1HnfUykjHatr46/sVvHykhs4+E5nxYfzbNXO5bfkMpkVZ6++zp0Xw9IEKnj5QwZevnO1QXJ4gCVwI4XUWi2Z7QSVrsuPJiA936NrclEi25VdQ195LSnSoXddUtXZz82/3YTDAxoUpbM5LY2VW3EU/ALITI1g/N5G/HjjLQ+uzCQrwrW5D34pGCDEl7T/TTGVLz0XLxtojN8XxjswXCqvpN1t44yvr+OWmJayaGT9m6/3eNZk0dvTxapHv7d0uCVwI4XXbD1YSHRrINfOTHb52bvLglHo76+Baa14orGL1zDi7WvvrZicyMzGcJ/aW+9zKh5LAhRBe1drVz+vFddy8NPW8XXfsFRUSyIzYUI7b2QI/dLaV8uZubl02w67zDQbFfWsyOVrVRmHFOYfjcydJ4EIIr3rxsLWc4Wjn5Ug5Dkyp31FYRWigkesWpox/8qBbls0gMiSAJ/aWORuiW0gCF0J4jdaa7QcrWTQjmnnTo5y+T25KJGfsmFLfO2DmlSO1XLcgmYhg+8dwhAcHcMeKNHYW11Hb1uN0nK4mCVwI4TVHq9ooqetwqvNypNyUKMwWzakG27vU/+PDejr6TNy63L7yyUifuiQTrTV/2X/W2TBdThK4EMJrnjlYSWigkRsXT5/QfXKS7VsbfMehKqZHh3DJzHiHn5EWF8aVudPYll/hM4tnSQIXQnhFd7+Jl4/UsHFhCpEho++6Y6+M+HBCAg02OzLr23t5t7SRm5elYjDYP+FnpPvWZtHaPcDfD1c7G6pLSQIXQnjFq0dr6ewzccfKiZVPAIwGxdzkKJtT6l/8oBqLtnZIOmv1zDhykiMdHlLorha7JHAhhFdsP1jJzMRw8jJiXXK/3ORIjo+xS73Wmh2FVSxNjyE7McLpZyiluG9tJiV1Hew/02zXNbtLGvjYT3ZTWNHq9HPHIglcCOFxpxo6KDjbyua8NIfWL7ElNyWK1u4BGjr6LvqsuLqdk/Wddo/9tuWmJanEhgWydW+5zfPMFs3P3zjBfVsPkhQZTHx40ISffaFxE7hSaotSqkEpVTzi2Hal1OHBX+VKqcMuj0wI4RN2FtVywM7Wpr2eLagiwKAmVM64kK2OzB2FVQQFGPj4ool1lgKEBBr55Kp03jxeT2XL6GuFN3f28aktB/jN7lNszkvjhYfXOLzGiz3saYFvBa4deUBrvVlrvURrvQTYAbzg8siEEF6lteanr5fw0FOFfP/lD112336TddedK3OnuXSJ1uHNHS7Y5LjfZOHvh6u5Knca0WET6ywdcs/qTAxK8eS+8os+O3S2lesffY+C8lZ+etsifnLbIqdmmNpj3ASutd4DtIz2mbL+22cTsM3FcQkhvGjAbOHrzx3ld2+fJjUmlJK6dtp6Blxy77eO19Pc1c9mF3RejhQdFkhqTOhFLfDdJxpo7R6wa49NeyVHh3DdgmS2F1TS1WcCrD/wtrxXxuY/7CcowMALD6+Z0OxSe0y0Bn4pUK+1Lh3rBKXUA0qpAqVUQWNj4wQfJ4Rwt+5+E5/7cwE7Cqv46pVz+Nlti9Aal3XCbS+oJCU6hHWz7dt1xxE5yZEXrUq441AVCRHBLn/efWuz6Og1saOwis4+E1/c9gH/9cqHrJ+bxMtf+hjzp0e79Hmjmeh64HcyTutba/048DhAXl6eby3lJYQ4T3NnH5/ZepCi6jZ+dMtC7lyZTne/iQCDoqC8hQ1zkyZ0/5pzPbxzspEvbZiF0cmx2LbkpETyzslG+kxmggOMtHT1s/tEA5++JNPuXX7stSw9hsUzovnju2fYuq+c8qYuvnVdDp9fN9NlHbPjcfo7UkoFALcA210XjhDCWyqau7ntsf2U1HXwh3vyuHNlOgBhQQHMT43mYNnEW+DPFVQBcLubSgu5KVGYRkypf+lwNQNm7dTU+fFYhxRmUdnSQ3uPiafuX82Dl2V7LHnDxFrgVwIlWusqVwUjhPCO4uo27n3iIANmC09/bhXLM+LO+3xFRix/fv/scMvWGRaL5tmCStZmJ5AWF+aKsC8ycpf6+dOj2VFYzbyUqOFNH1zthkUp9A6Y2ZCTNLwNmyfZM4xwG7AfmKuUqlJKfXbwozuQzksh/N7eU03c8fj7BBkVOx665KLkDbAiK45+k4Wiqjbnn3O6iepzzu26Y6+shHCCAwwcr23nZH0HRdVtbml9DwkwGrhjZbpXkjfY0QLXWt85xvF7XR6NEMKjXi+u40vbCpmZEMGTn1lJcvToiWhotuTB8lbyMi9O8PZ45mAlMWGBXD1/mtPxjsc4vEt9BzsKrWPNb1oy8bHfvkpmYgoxRWmt+cGrHzI7KZJnH7xkzOQNEB8RTHZiOAfLRx1RPK6efjP//LCemxZPd7oEY6+c5Eg+rG3nxQ+qWT83kYQI14019zWSwIWYoo7VtFPV2sO9azKJDh1/gsuKzDgKyluwWBwfTLb3VBN9JgtXzXN8z0tH5aZE0dLVT317n0umzvsySeBCTFE7i2sxGhRXzbOvpLEiM472XhOl42yaMJq3SuqJCA5gZZZz5RdHDHVkRocGcnnuxIY9+jpJ4EJMQVprdhbXsXpmHLF2LrK0YrD2ne9gGcVi0bx1vIF1cxIICnB/yslNicSg4EYPlGu8baITeYQQDngmv4Lfv3Oa5emxXJIdzyXZ8cyIdc+QOltKGzo509jFfWuz7L4mLS6UpMhgCspbuGd1ht3XHatpp6Gjjyty3Nd5OVJMWBB//ewq5qe6fyakt0kCF8KDtu4rp6vPxNsnG3nhA+uuLulxYawZTOaXZMeTFOn+IWk7i+pQCq5xYESIUooVWXEcLHOsBf7P4/UYFGzI8Vw5Y82sBI89y5skgQvhIacaOiip6+CRG+dzz+oMTjZ0sO9UM/vPNPNqUS3PHKwEYFZSBLcum8FD67PdFsvO4lryMmId/mGxIiOWV4/WUn2uh9SYULuueauknmXpscS5YT3sqU4SuBAe8vKRWpSC6xYkYzAocpKjyEmO4jMfy8Js0RyraWPf6WZ2HW/gJ6+XkBIdwieWum4FvSFlTV2U1HXw3RvmOXztisFOyINlLaTaEVtdWy/F1e1849q5Dj9LjE86MYXwAK01rxytYVVWHEmjzNozGhSLZsTw4GXZg1PZY/nui8VjbhgwETuLawG4doHjQ/pykqOIDA6wezz4rpIGAK7M9Uz9e6qRBC6EB5yo7+B0Yxc32LEjTIDRwK82L0EDX3v2CGYnxl3b8npxHYvTYuwugYxkNCiWZcRSUG7fwlZvHa8nLS6U2UnO70MpxiYJXAgPeOVILQZlf6s3LS6MR26cT355C4+9c9plcVS1dnO0qo3rnGh9D1mRGcuJ+g7OdffbPK+n38x7p5q4ImeaR1fom0okgQvhZkPlkzXZCQ5N675lWSo3LErhf948ydGqcy6J5fXiOoAJJfChtVAOnbXdCt932jr78opJPpnGmySBC+Fmx2raKW/u5oZFKQ5dp5Tih59YSFJkMF9+5jDd/aYJx/J6cR25KVET2mB3SVoMgUY17oSefx5vIDzIyKqseKefJWyTBC6Em71ytJYAg+Ka+Y63eqPDAvnFpiWUN3fx369MbGPhhvZeDlW0Tqj1DdZd2RemRtusg2ut2VVSz7o5iR6ZfTlVyZsVwo2GyidrZyXYPWX9Qpdkx/P5ddlsy6/kjWN1TsfyxrE6tJ5Y+WTIiqw4jlado3fAPOrnx2raqW/v4woZfeJWksCF3xowW3itqBatfXer1aNVbVS19jhcPrnQv141hwWpUXxrx1Ea2nudusfO4jqyE8OZPS1yQrEArMiIY8CsOVI5em3+n8frUQo2zHX9xsXiI5LAhd96vbiOh58qZP+ZZm+HMqZXjtYQaFRcPcFlVIMCDPxq81J6Bsx87bkjDi/p2tzZx4GyFq5bMLEfJEPyMq0bPBSM0ZH51vEGlqbFED+J1+L2BZLAhd86UdcBYPeYZE+zWDSvHq1l3exEosPGX297PLOSIvjO9fN4t7SJrfvKHbr2zQ/rMVu0U5N3RhMTFsScaRHkj7IuSn17L0XVbVI+8QBJ4MJvlTZYE/h4w9m85YPKVmraerlhsWtavQB3rUrnytwkfvx6CSV17XZft7O4jrS4UOZPd93mvnmZcRSebb1oopHMvvQcSeDCb5XWWzcWKKxodWqXGHd75WgtQQEGlyYypRQ/vnURUSEBPPzXQqrP9Yx7TVvPAPtON3HdghSXTqhZmRlHR5/poh8kbx2vJzUmlDnTZPalu0kCF36pz2SmvLmLtLhQOnpNnBxsjfsKi0XzWlEt6+ckEhky8fLJSAkRwTx293IaO/u49Xf7hktJY3nreD0DZu2S0ScjDdfBR5Swegessy+vzE2S2ZceIAlc+KWypi4sGjbnpQG+V0Y5WN5CfXsfNyx2z47oeZlxPPfgJWg0tz22jwM2OnJ3FteREh3C4hkxLo1hRmwY06NDzpvQs+90E70DFql/e4gkcOGXTg6WT67InUZCRBCHfKwj89WiWkICDVzhxk0McpKjeOHhtSRFBnPPlnx2FtVedE5Xn4k9Jxu5Zr51CVtXyxvc6HhoKOfw7MuZ7t/7UkgCF37qVH0HRoNiZmI4yzNixxzOZo/ufmuScxWzRfNaUR2X5yQRHuzeJfdTY0J5/sE1LJgexcNPF/KX98+e9/nuEw30mSwuL58MWZEZS317H1WtPdbZl8cbuHR24qTfi9JXSAIXfulkfScZ8WEEBxjJy4ijoqWbhg7nJrg8sbecT23Jt3uN6/EcONNMU2efXUvHukJseBBP3b+aK3KS+O6LxfziHyeGW8Q7i+tIiAgaXoDK1YY2eMgva+FYTTt17b2yeJUHSQIXfqm0oWN4jellGdbOtEInW+G7B4e9bd1b7pLYXimqJSzIyIa5nktkoUFGHrt7OXesSOPXu07xzR1H6ewzsbukgavnJ2N0Q/kEYE5SJFEhARScbeGt4w3W2Zce3Ptyqhs3gSultiilGpRSxRcc/5JS6oRS6phS6qfuC1GI81lHoHQzO8k6JXxBahRBAQanJvSc6+6nsKKVqJAAXj9WR40dw/JsMZktvF5cxxW50wgN8mwZIcBo4Ee3LORfrpjNswVV3Pib9+juN7utfAJgMCjyMuPIL2vhrZJ6lqTFOLRkrpgYe1rgW4FrRx5QSm0AbgIWaa3nAz93fWhCjK68qRuzRTN7cJxxcICRxTOiOVTheALfU9qERcMPb16I1po/7z87/kU27DvdTEtX/4TXPnGWUop/vWoOP/jEAsqauogODWT1TPcu55qXGcvpxi6OVrXJ5B0PG7eHRWu9RymVecHhh4Afa637Bs9pcH1oQoxuaAbmUAscrGWULe+V0TtgJiTQ/pbv2yUNxIYFsnFhCq8V1bItv4IvXzHb6dbzK0driAgO4LI53l3E6e7VGcxMDMds0QQa3VspXTmivn65lE88ytn/s3OAS5VSB5RS7yilVox1olLqAaVUgVKqoLHRdT39Yuo6Wd+JQcHMxI82JcgbXB3vaFWb3fexWDTvnGxk3ZxEjAbFvWsyaesZ4MXD1U7F1W+y8Maxeq6aN82hHyLusiY7gUtnu/8HycIZ0QQFGEiNCSUneeIrHQr7OZvAA4BYYDXwb8CzaoxpV1rrx7XWeVrrvMREWVpSTNyphg4y4sPPS5LLBzsyHZnQU1TdRnNX/3Bn48qsOOalRPHE3jKnlqjde6qJtp4Br5VPvCU4wMh9azJ58LKZMvvSw5xN4FXAC9oqH7AACa4LS4ixnazvZNYFu5zHhQcxMyGcQ2ftHwq4+4R11MS6wXKHUor71mZysr6TfacdW6LWZLbwyzdPkhAR7JFWr6/594253HNJprfDmHKcTeAvApcDKKXmAEFAk6uCEmIs/SYL5U1doy6UtDwjlkNnW+1uPe8+0ciStBjiRuyU8/HF04kPD+KJvWUOxfWn98ooqm7jkRvnyxZiwmPsGUa4DdgPzFVKVSmlPgtsAWYODi18Bvi09uVtUcSkUd7chcmiz+vAHJKXGUtr9wBnmrrGvU9TZx9Hq85dNFY7JNDIXavSeaukgbPN498HrOuy/PLNk1w9bxobF7pvyJ4QFxo3gWut79Rap2itA7XWM7TWf9Ja92ut79ZaL9BaL9Na7/JEsEIMLSE7e4wWOGDXuih7TjaiNaNOtrlrdQZGpXhy3/hDCi0WzTd3HCUowMAPPrFAasDCo+TfesKvlDZ0YFCQnXhxAp+ZEEFMWCAFdtTBd59oJCEieNQNDqZFhXD9ohSeK6iks89k8z5P51eQX9bCd6+fR1JUiP3fiBAuIAlc+JXS+k7S48JGHaZnMCiWp8eOOxLFbNHsOdnI+rmJY67Qd9/aLDr6TDxfUDnmfWrO9fDjnSWsnRXP7XkzHPtGhHABSeDCr5Q2dDBrlPr3kGUZ1lmBrV39Y55zuLKVtp4B1tvYMX1JWgxL02N4cv/ZUXf70VrznReLMVs0P7p5kZROhFdIAhd+Y8Bsoaypa9T695A8O8aD7y5pxGhQXDrL9nC/e9dkUtbUxTujLDX70pEadpU08PVr5pIeH2bndyCEa0kCF37jbHMXA2Ztc6/FxWkxBBiUzXVRdp9oYHl67Lg7xW9cmMK0qGC2XDCksKmzj++/dIyl6THcuybToe9BCFeSBC78xvAIFBsllJBAI/NTo8cciVLf3suxmnbW54w/2SbQaOCe1Rm8W9rEqRF7bj7y8od09Zn56a2L3LZMqxD2kAQu/MbJ+k7UGCNQRsrLiOVI1Tn6TZaLPnvnhLUcYu9a3XeuTCcowMATg2uFv/lhPS8fqeGLl89i9jRZ90N4lyRw4TdKGzpIiw0bd6XAvIxY+kwWjtVcvLDV7hMNJEeF2L3oUnxEMDctns4LhdVUtnTznReLyEmO5MHLsp36HoRwJUngwm+U1ncO78Jjy1gLWw2YLbxX2sSGnESHRo3ctzaLngEztz+2n8aOPn5y6yKZLi98gvwpFH7BZLZwpqnTrrJFUlQIaXGhFyXwQ2db6egzsd7Brc7mTY9iVVYcde293H/pTBanxTh0vRDuIglc+IXy5m4GzNquFjhY1wcvuGBhq90nGgg0KtbOcnzhzP/YmMvty2fw1SvnOHytEO4iCVz4haFRIHPs7DhclhFLY0cflS0f7XH5dkkjKzLjiAgedyOqiyxOi+Fnty/2+D6XQtgiCVx4xamGDoc2TRgaQpidFD7OmVbDE3oqrOuiVJ/r4UR9h0d3ihfC3SSBC487UnmOK3+5h5eO1Nh9zcmGTtLiQgkLsq/1PGdaJJHBAcM71b99wrpt6wY7xn8L4S8kgQuPe/+MdbcbR3aAL63vsDmB50JGg2JJesxwR+bukkZmxIaOO4ZcCH8iCVx4XOHgNPdDZ1s5Xts+7vkms4UzjV12d2AOycuI40R9B02dfew73cSGuUmy6JSYVCSBC4/SWlNYcY4NcxMJDjDw1/fHb4VXtHTTb7Y4PPMxLzMWreHxPWfo7jdL+URMOpLAhUdVtfbQ2NHH5TlJ3LBoOi9+UD3upgknh9dAcawFvjgtBoOCJ/eVExRg4JKZsu+2mFwkgQuPGiqfLE2P5e7V6XT1m/nbB9U2rxkaQnjhTvTjiQgOIDclij6ThdUz42UIoJh0JIELj/qg4hyhgUZykiNZkhbD/OlRPPX+WZtDCksbOkmNCSXcifHbQ8MJN9jYvEEIfyUJXHhUYUUri2ZEE2A0oJTi7tUZlNR12NyA4WR9p801wG1ZPzeJoAADV+ZOczZkIXyWJHDhMb0DZj6saWfZYKsY4MbF04kIDhizM9Ns0ZxutG8NlNFsyEniyPeuJi1Ods0Rk48kcOExR6vaMFk0y9I/SuDhwQHcsiyV14rqaO7su+iaipZu+k0Wh+vfI0ntW0xWksCFx3zUgXn+an53r86g32zhuUNVF11TWu/YGihCTCWSwIXHFJ5tJSM+jISI4POOz5kWycrMOJ4+UHHRDvClDdYhhBNpgQsxWY2bwJVSW5RSDUqp4hHHvq+UqlZKHR78tdG9YQp/NzSBZ2T5ZKS7VqdT0dLNntLzd4Avre8gNSbUqRUEhZjs7GmBbwWuHeX4/2itlwz+es21YYnJpqq1h6bOPpalj74ZwrULkokPD+Kv71ecd7y0oVNa30KMYdwErrXeA7R4IBYxiY2cwDOa4AAjm1aksauknupz1jW8zRbNqQb7tlETYiqaSA38i0qpo4MlltH/VgJKqQeUUgVKqYLGxsaxThOTXOHZVsKCjDY3E/7kynQ08Ey+tRVe1dpNn8kiHZhCjMHZBP57IBtYAtQCvxjrRK3141rrPK11XmKizIbzd45swjBSYcW54Qk8Y0mLC2P9nESeOVjJgNkyvAbKLCcn8Qgx2TmVwLXW9Vprs9baAvwRWOnasIQv+rCmnbU/3sXukgaHruvpN3O8tn3MDsyR7l6dQWNHH/84Vk/p4BooUkIRYnROJXClVMqI394MFI91rpgc2noGeOipQ9S09fL4njMOXVtUffEEnrGsn5tEakwof33/LKfqO0mJDiEyJNDZsIWY1OwZRrgN2A/MVUpVKaU+C/xUKVWklDoKbAC+6uY4hRdZLJqvPXuY6tYerluQzP4zzZQ3ddl9/VgTeEZjNCg+uSqd/Wea2VPa5PQUeiGmAntGodyptU7RWgdqrWdorf+ktb5Ha71Qa71Ia32j1rrWE8EK7/jd26f45/EGvnvDPL5/43wMCp4tqLT7+sKzrWTGhxF/wQSesWzKSyPQqGjq7JPyiRA2yExMYdOek4384s2T3LRkOp+6JINpUSFsmJvE84eqMJkt414/3gSe0SRGBnPN/GRA6t9C2CIJXIypqrWbLz/zAXOSIvnRLQuH95PcvCKNho4+3j4x/rDQoQk8SzPsT+AAn/1YFqGBRvIyHbtOiKlEErgYVZ/JzBeeKsRk1jx2z3LCgj6ayr4hJ4nEyGCeOTh+GWWo/j3WDMyxLE2P5dgj1zDLgZ3ohZhqJIGLUT3y8occqWrj55sWk5UQft5ngUYDty6bwe4TDTS099q8z9AEnrlOdEYaDLKDvBC2SAIXF3muoJKnD1Tw0Prs4Vr0hTavSMNs0TxfePESsCMVVpxj8YwYmxN4hBDOkb9V4jzF1W1858Vi1mTH87Wr5ox5XlZCOKuy4th+sHLM2ZnDE3gyHCufCCHsIwlcDGvrtk7WiQ0L4tE7l47bat68Io2zzd28f2b0tc6OVp3DZNEsTZOOSCHcQRK4j3v1aC1vn2hweg0Se1ksmq8+e5i6tl5+d/eyizZdGM11C1KIDAlg+8GKUT8vrDgH2DeBRwjhOFkl34eVN3XxxW2FaF4ekZ4AABFOSURBVG0dxfG1q+eyJjt+eDifK/161yl2lTTw3zfNt3vMdmiQkU8sSeXZgkoe6R4gOuz8Ke+FFY5N4BFCOEZa4D7s/947Q6DBwLc35lLb1std/3eAO//4PgfLXbs8+9snGvjVWye5eWkqd6/OcOjazSvS6DNZ+PuR6vOOa635oKLVoQk8QgjHSAL3Uc2dfTxXUMXNS1P53LqZ7P76er7/8Xmcauji9sf286kt+RypPDfh51S2dPOV7YeZOy2S/3fzQodb9wtSo5k/PYpt+ed3Zla29NDU2e/wBB4hhP0kgfuoJ/efpc9k4XPrsgAICTRy79os3v3GBv5jYw5FVee46bd7uf/JAj6saXfqGb0DZh5+qhCzRfPY3csJDTI6dZ87VqRxvLad4uqP4nB2Ao8Qwn6SwH1QT7+Zv+wv58rcaRfNRAwNMvLAumze/eblfO2qORwoa2bjo+/y3ReL6TOZHXrO9186RlF1G7/ctITMCybrOOLGJakEBxjYXvBRZ2ZhhfMTeIQQ9pEE7oOeO1RJa/cAn79s5pjnRAQH8KUrZvPeNy7nvrWZ/OX9s2x6bD9Vrd12PWP7wQqeOVjJFzZkc9W8aROKNzo0kI0LU/j7BzX09Ft/iBRWtMoEHiHcTP52+RiT2cL/vVvG0vQY8uyoH0eHBfKfH5/PY3cv50xjFzf8+j3ePmF7x5yiqja++/djfGxWAv961VyXxL15RRodfSZeK6qlu9/E8doOmcAjhJtJAvcxrx+ro6Klm8+vy3aoQ/HaBcm89KWPkRwVwn1bD/LLN09itlw8dry1q5+HnjpEQngQ/3vHEowuWm9kVVYcmfFhbC+o5GhVG2Y7d+ARQjhPErgP0Vrz+J4zZCWEO1XWyEoI528Pr+WWpTN49K1S7n0in5au/uHPzRbNV7YfpqG9j9/dvdyl47OVUmxakUZ+WQs7DlnXR1kqCVwIt5IE7kPeP9PC0ao27r80y+mWcWiQkZ/fvogf3bKQA2UtXP/ou8MjQh59q5R3TjbyvY/PY0ma68sbty2bgdGgeO5QFVkJ4cSFB7n8GUKIj0gC9yGP7zlNQkQQty6bMaH7KKW4c2U6Lzy0BqNBsfkP+/n234r437dKuXXZDO5ale6iiM+XFBXC5TlJgEyfF8ITJIH7iBN1Hew+0cinL8kkJNC58dgXWpAazatfupR1sxN56kAFuSlR/OATC9wyFX/IHSvSAFguE3iEcDtZC8VHPL7nDKGBRoenso8nOiyQP34qj53FdazIjHV6so69Ls9J4td3Lp3w0EQhxPgkgfuAurZeXjpSzV2rMoh1Q93YYFBcvyjF5fcdjVKKjy+e7pFnCTHVSQnFBzyxtwyLtm7kK4QQ9pIE7mXtvQM8daCCjQtTSIsL83Y4Qgg/Igncy7YdqKCzz8Tn1409bV4IIUYjCdyL+k0WnthbztpZ8SxIjfZ2OEIIPzNuAldKbVFKNSilikf57OtKKa2USnBPeJPbS0dqqGvv5YF12d4ORQjhh+xpgW8Frr3woFIqDbgKGH1DRDGuJ/aWkZMcybrZ8vNPCOG4cRO41noPMNoeXv8DfANw7267k1RzZx/Hatq5ccl0t06sEUJMXk7VwJVSNwLVWusjdpz7gFKqQClV0NjY6MzjJqWhfS1XZcV7ORIhhL9yOIErpcKAbwPfs+d8rfXjWus8rXVeYmKio4+btA6UtRASaGChdF4KIZzkTAs8G8gCjiilyoEZQKFSKtmVgU12+WUtLEuPJShABgIJIZzjcPbQWhdprZO01pla60ygClimta5zeXSTVFvPAB/Wtkv5RAgxIfYMI9wG7AfmKqWqlFKfdX9Yk9uhsy1oDSuz4rwdihDCj427mJXW+s5xPs90WTRTxIGyFoKMBlkzWwgxIVKA9YIDZ1pYnBbtsnW/hRBTkyRwD+vqM1Fc3SblEyHEhEkC97APKs5hsmhWSgemEGKCJIF72IGyZowGJVuOCSEmTBK4hx0oa2HB9CgigmUzJCHExEgC96DeATOHK89J/VsI4RKSwD3oSOU5+k0WqX8LIVxCErgH5Ze1oBSszJQWuBBi4iSBO+HfXyjiRzuPO3xdfnkLc6dFEh0W6IaohBBTjSRwB+073cS2/Ar+9G4Z9e29dl83YLZw6Gwrq6T+LYRwEUngDrBYND989TiJkcGYteav75+1+9ri6ja6+82smin1byGEa0gCd8CLh6s5VtPOd67P5YqcJJ4+UEHvgNmua/PLrBs4rJD6txDCRSSB26mn38zP3jjBohnRfHzRdO5bm0VzVz8vH6mx6/oDZS3MTAwnMTLYzZEKIaYKSeB22rK3jNq2Xr69MReDQbEmO5450yJ4Ym85WtveFtRs0Rwsb5H1v4UQLiUJ3A6NHX38bvcprp43bbiGrZTi3jVZfFjbPlweGUtJXTsdvSbpwBRCuJQkcDv86p8n6TNZ+NZ1Oecdv3lpKjFhgWzdV27z+gNnrAleZmAKIVxJEvg4Sus72JZfwd2rM5iZGHHeZ6FBRu5Ykc4bx+qoau0e8x75ZS3MiA1lekyou8MVQkwhksDH8aOdJYQHBfAvV8we9fNPXZKBUoq/7B99SKHWmnypfwsh3EASuA17TzWxq6SBL1w+i7jwoFHPmR4TyrXzk9mWX0F3v+miz081dNLS1S/1byGEy0kCH4PZovnBq8dJjQnl3jWZNs+9d20m7b0m/vZB9UWfHSiT+rcQwj2mVAI/191PRfPYteqRXiis4nhtO9+4du64e1fmZcSyIDWKraMMKcwva2FaVDAZ8WFOxy2EEKOZMglca839Txaw7me7ufX3+9h+sILOvotLHmCdtPPzf5xgcVoMNy6ePu69lVLctyaL0oZO3jvVdN4zD5Q1szIrHqWUy74XIYSAKZTA959upuBsK9cvTKGtZ4Bv7ihi5Q//yb89d4SC8pbzWs5/fPcM9e19fHtjrt2J94bFKSREBPHE3vLhYxUt3dS390n5RAjhFlNmX69Hd5UyLSqYX2xaTHCAgcKKczx7sJJXjtbw3KEqZiaGsykvjUtnJ/DYO6e5Zv40hxJvcICRT67K4NG3Silr6iIrIXy4/r1aErgQwg2mRAv8YHkL759p4YF12YQEGlHKuqnwT25bRP63r+Snty0iLiyIH+8s4fpH36PfZOFb1+U6/Jy7V6cTaFQ8OTix58CZFuLCg5iVFGH7QiGEcMK4LXCl1BbgBqBBa71g8Nh/AzcBFqABuFdrbd+qTl7w612nSIgI4pMr0y/6LDw4gE15aWzKS+N0Yyc7DlWRHhdGVkK4w89JigzhhkXTef5QFV+7eg755c2syIyV+rcQwi3saYFvBa694NjPtNaLtNZLgFeA77k6MFc5XHmOPScbuf/SmYQG2R5Nkp0YwTeuzeGOURK9ve5bm0lnn4lf7zpFZUuPTOARQrjNuAlca70HaLngWPuI34YDtpfj86Lf7DpFTFggd6/O8MjzFs2IYXlGLH989wwg47+FEO7jdA1cKfVDpVQlcBc2WuBKqQeUUgVKqYLGxkZnH+eUD2va+efxej6zNouIYM/11967JhOtITI4gNyUKI89VwgxtTidwLXW39ZapwFPAV+0cd7jWus8rXVeYmKis49zym92lxIZHMCnx5lJ6WrXLkgmNSaU1dnxGA1S/xZCuIcrmqVPA68C/+mCe7lMaX0HO4vr+ML6WUSHenYX+ECjgR0PrSE4YEoM8hFCeIlTGUYpNXJpvhuBEteE4zq/3X2K0EAjn/lYlleenxwdQuwYC2AJIYQr2DOMcBuwHkhQSlVhbWlvVErNxTqM8CzwoDuDdFRZUxcvHanh/ktnjrmKoBBC+LtxE7jW+s5RDv/JDbG4zO/fPkWg0cD9l3qn9S2EEJ4w6Yq0lS3dvFBYzZ0r00mKDPF2OEII4TaTLoH/Yc9pDErx+ctmejsUIYRwq0mVwOvaenn2YBW35c0gJVr2nxRCTG6TKoH/Yc9pzFrz0GXZ3g5FCCHcbtIk8MaOPrblV3Dz0lTS4mT3GyHE5DcpErjZovnRa8fpN1n4woZZ3g5HCCE8wu83dOgdMPOVZw7z+rE6/uWK2U4tAyuEEP7IrxN4W88An/tzAfllLXz3hnl81kuzLoUQwhv8NoHXtvVw75aDnGnq5NE7l9q1+bAQQkwmfpnAS+s7+PSWfNp7TWy9byVrZyV4OyQhhPA4v0vgBeUtfPbJAgKNBp55YDULUqO9HZIQQniFXyXwfxyr40vbPmB6TCh//sxKGS4ohJjS/CaBP32ggu+8WMTC1Gi23LuC+Ihgb4ckhBBe5RcJ/Le7T/GzN06wfm4iv7trGWFBfhG2EEK4lV9kwqyEcG5fPoP/d8tCAo2TYu6REEJMmF8k8I0LU9i4MMXbYQghhE+R5qwQQvgpSeBCCOGnJIELIYSfkgQuhBB+ShK4EEL4KUngQgjhpySBCyGEn5IELoQQfkpprT33MKUagbNOXp4ANLkwHE+QmN3P3+IFidlT/C1mW/FmaK0TLzzo0QQ+EUqpAq11nrfjcITE7H7+Fi9IzJ7ibzE7E6+UUIQQwk9JAhdCCD/lTwn8cW8H4ASJ2f38LV6QmD3F32J2OF6/qYELIYQ4nz+1wIUQQowgCVwIIfyUXyRwpdS1SqkTSqlTSqlveTseeyilypVSRUqpw0qpAm/HcyGl1BalVINSqnjEsTil1JtKqdLB/8Z6M8YLjRHz95VS1YPv+bBSaqM3Y7yQUipNKbVbKXVcKXVMKfXlweM++a5txOuz71kpFaKUyldKHRmM+ZHB41lKqQOD73i7UirI27EOsRHzVqVU2Yj3vMTmjbTWPv0LMAKngZlAEHAEmOftuOyIuxxI8HYcNuJbBywDikcc+ynwrcGvvwX8xNtx2hHz94Gvezs2GzGnAMsGv44ETgLzfPVd24jXZ98zoICIwa8DgQPAauBZ4I7B448BD3k7Vjti3grcZu99/KEFvhI4pbU+o7XuB54BbvJyTH5Pa70HaLng8E3Ak4NfPwl8wqNBjWOMmH2a1rpWa104+HUHcBxIxUfftY14fZa26hz8beDgLw1cDjw/eNxn3jHYjNkh/pDAU4HKEb+vwsf/QA3SwD+UUoeUUg94Oxg7TdNa14L1LzKQ5OV47PVFpdTRwRKLT5QiRqOUygSWYm1t+fy7viBe8OH3rJQyKqUOAw3Am1j/1X5Oa20aPMXn8saFMWuth97zDwff8/8opYJt3cMfErga5Zg/jH1cq7VeBlwHfEEptc7bAU1SvweygSVALfAL74YzOqVUBLAD+IrWut3b8YxnlHh9+j1rrc1a6yXADKz/as8d7TTPRmXbhTErpRYA/w7kACuAOOCbtu7hDwm8Ckgb8fsZQI2XYrGb1rpm8L8NwN+w/qHydfVKqRSAwf82eDmecWmt6wf/IliAP+KD71kpFYg1GT6ltX5h8LDPvuvR4vWH9wygtT4HvI21nhyjlAoY/Mhn88aImK8dLGFprXUf8ATjvGd/SOAHgdmDPcpBwB3AS16OySalVLhSKnLoa+BqoNj2VT7hJeDTg19/Gvi7F2Oxy1ASHHQzPvaelVIK+BNwXGv9yxEf+eS7HiteX37PSqlEpVTM4NehwJVYa/e7gdsGT/OZdwxjxlwy4oe6wlqzt/me/WIm5uCQpV9hHZGyRWv9Qy+HZJNSaibWVjdAAPC0r8WslNoGrMe6hGU98J/Ai1h77tOBCuB2rbXPdBqOEfN6rP+s11hH/nx+qLbsC5RSHwPeBYoAy+Dh/8BaV/a5d20j3jvx0feslFqEtZPSiLVR+qzW+r8G/x4+g7UU8QFw92DL1utsxLwLSMRaOj4MPDiis/Pi+/hDAhdCCHExfyihCCGEGIUkcCGE8FOSwIUQwk9JAhdCCD8lCVwIIfyUJHAhhPBTksCFEMJP/X8ayv576M9I3AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(len(overallscores))\n",
    "plt.plot(x,overallscores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
